\documentclass[12pt]{article}
 
\usepackage[T1]{fontenc}     
\usepackage[utf8]{inputenc}  
\usepackage[magyar]{babel}   
\usepackage{lmodern}
\usepackage{caption}       
\usepackage{makecell}
\usepackage{boldline} 
\usepackage{cite}
 
\usepackage{amsmath,amssymb}
\usepackage{tikz, pgfplots}
\usetikzlibrary{positioning}
\usepackage{arydshln}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{booktabs} 
\usepackage{amsthm}          
\usepackage{graphicx}  
\usepackage{hyperref}  
\usepackage[export]{adjustbox}
\usepackage{wrapfig}
\usepackage{float}
\usepackage[a4paper, left=25mm, right=25mm, top=25mm, bottom=25mm]{geometry}

\usepackage{mathtools}

\usetikzlibrary{positioning,arrows,fit}

\renewcommand\vec[1]{\boldsymbol{#1}}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}   

\newtheorem{definition}{Definíció}[section]

\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}


\title{Covid-19-cel kapcsolatos tévinformációk azonosítása gépi tanulással}
\author{Köller Donát, BME TTK BSc. Szakdolgozat}
\date{\today}           
\captionsetup[table]{position=bottom}            
 
\linespread{1.2}

\begin{document}


\begin{titlepage}
\begin{center}
       \includegraphics[width=0.6\textwidth]{kepek/bme_logo_kicsi}
       \rule{15cm}{0.1mm}
       
       \vspace*{0.5cm}
       
       
       
       \huge{TDK DOLGOZAT} \\
       
       

       \vspace{1cm}
        \Large{\textbf{Elsőéves hallgatók pandémia előtti és alatti bemeneti}} \\
        \Large{\textbf{adatainak elemzése modern adattudományi eszközökkel}} 
        
        \vspace{1.8cm}
        
        \large{\textbf{Köller Donát Ákos \& Vlaszov Artúr}}\\
       \large{BME Matematikus MSc} \\
       %\large{Adattudomány szakirány} \\
       
       
       \vspace{1.8cm}
               

      \large{\textbf{Témavezető: Szilágyi Brigitta}}\\
      \large{Geometria Tanszék}
            
       
            
       \vfill
     
       \includegraphics[width=0.3\textwidth]{kepek/bme_cimer}\\
       \large{BME Matematika Intézet} \\
       \large{Budapest} \\
       \large{2022}
            

            
   \end{center}
\end{titlepage}
\newpage

\tableofcontents
\newpage


\section{Bevezetés}
Az elsőévesek képességének és készségeinek mérése nemcsak a felsőoktatásban bevett gyakorlat, hasonlóval találkozhatunk akkor is, amikor például a diákok a gimnáziumi tanulmányaikat kezdik meg, de bevett gyakorlat a szintfelmérő a nyelviskolákban is a nyelvi szintek megállapításánál. A felsőoktatásban leginkább arra használják a bemeneti méréseket, hogy feltérképezzék, a hallgató birtokában van-e az adott tárgy teljesítéséhez szükséges előismereteknek. Amennyiben nincs, felzárkóztató kurzusokat biztosítanak. Előfordulhat az is, hogy valamely egyetemi tárgy teljesítése szempontjából szükséges kritériumként fogalmazzák meg a bemeneti tesztek adott szint fölötti teljesítését. Előfordul, hogy ezekhez a tesztekhez mindenki által hozzáférhető gyakorló feladatokat is rendelkezésre bocsátanak vagy elérhetővé teszik a korábbi évek feladatsorait. Tekintettel arra, hogy a hazánkban tematikus és szintek szerinti bontásban az érettségizők rendelkezésére állnak a korábbi évek feladatsorai (\url{https://www.studiumgenerale.hu/matek-erettsegik/}), a tanulók rutinosak az ún. rátanulásban, amikor adott feladattípusok megoldásmenetét sajátítják el, nem egyszer mélyebb megértés nélkül. Több helyen bevett gyakorlat a mintadolgozat intézménye, ami esetleg azt is jelentheti, hogy a számonkérés alkalmával a diáknak egy a kiadotthoz teljesen hasonló feladatsorral kell megküzdenie. Ilyen mérések alkalmával azonban nem kapunk képet arról, miként fog teljesíteni a diák akkor, ha nemcsak begyakorolt rutinokból kell számot adnia a tudásáról. Éppen ezért ezek a mérések nem jelzik előre, hogy a hallgató meg tud-e birkózni a kalkulus tárgy nehézségeivel, sikeresen fogja-e venni azokat az akadályokat, amelyeket a matematikaigényes szaktárgyak jelentenek.

A Budapesti Műszaki és Gazdaságtudományi Egyetemen több éve foglalkozunk azzal, hogy az ütemterv szerinti haladást minél inkább előre jelző feladatsort készítsünk és ezzel mérjük az elsőéveseket. Az elmúlt években a mérőtesztek struktúrája is változott: az első idők matematika tesztjei nyelvi feladatokkal is kiegészültek. A pandémia okán nem minden esetben került sor jelenléti tesztelésre. Mostanra kellően nagy adatbázis áll rendelkezésünkre, amelyen nemcsak azt vizsgálhatjuk, milyen mértékben állnak készen a hallgatók arra, hogy sikerrel teljesítsék a kalkulus tárgyakat, hanem azt is, mennyire megbízható az online tesztelés, illetve milyen hatással volt a COVID-19 járvány az elsőévesek felkészültségére. Dolgozatunk célja, hogy modern adattudományi eszközök felhasználásával megvizsgáljuk a járvány kirobbanása előtt és után kezdett hallgatók bemeneti adataiban fellelhető változásokat, és ezen különbségek hatását az első félév végi teljesítményükre.

\newpage

\section{Irodalmi áttekintés}

Nemzetközi téren a járvány diákokra gyakorolt hatásáról számos kutatás készült az elmúlt években. A Cavannaugh et al. \cite{student_perf1} által vizsgált 837 amerikai tanuló hallgató esetén az átlagos tanulmányi átlag 0.1-gyel nőtt a pandémia alatt, és a növekedést legjobban befolyásoló tényező az egyes diákoknál az egyetemükön tanuló hallgatók száma volt. Ugyanakkor Alawamleh et al. \cite{student_perf8} munkája, valamint Yamini Chandra \cite{student_perf6} kutatása arra világítanak rá, hogy az online oktatás alatt gyakori volt a hallgatóknál a motivációhiány és az elidegenedés érzete is, valamint drasztikusan megnőtt a tanulókra és szüleikre nehezedő stressz illetve munka mértéke is.
Onyema et al. \cite{student_perf5} munkája azt a következtetést vonja le, hogy a digitális időszak negatívan érintette az oktatási tevékenységek jelentős részét, amely a tanulmányi teljesítmény csökkenése mellett diákhitel-növekedésben, egyetemi költségvetés-megvonásban és kutatási korlátozásokban is megnyilvánult. Ezek mellett az online oktatás hatékonyságát nehezítő körülmények közé sorolja a kiegyenlítetlen elektronikai infrastruktúrát, az oktatók elmaradott digitális készségeit, hálózati és szoftver elérhetőségi problémákat és más egyéb tényezőket is.
Összességében elmondható, hogy járvány rávilágított a hagyományos oktatási rendszerek sebezhetőségére, ugyanakkor motivációt is adott azok átértékelésére, korszerűsítésére és új online oktatási módszerek kialakítására egyaránt \cite{student_perf7, student_perf9}. 

A pandémia hatásáról a diákok teljesítményére vonatkozóan hazai szinten is készültek kimutatások. Monostori Judit \cite{magyar1} jelentésében többek között az olvasható, hogy a 2020/2021-as tanévben a magyar alsó- és középoktatásban tanuló diákok teljesítménye lényegesen elmarad a jelenléti oktatás során megszokott szinttől, illetve a legnagyobb kihívást a tanulók figyelmének fenntartása és a szociális elszigetelődés leküzdése jelenti. Az eredmények alakulásában továbbá sokszor nagyobb jelentőséggel bír a szülőktől kapott otthoni segítség, mint az elektronikus infrastruktúra helyzete.
Proháczik Ágnes \cite{magyar2} digitális oktatásról szóló felmérése arról számol be, hogy  a diákok, szülők és tanárok túlnyomó része jelentős többletidő-ráfordítással tud csak megbirkózni az online tanulás nehézségeivel. A plusz ráfordított idő mennyisége régiónként eltérő, azonban szoros összefüggésben van mind a diákok, mind a tanárok digitális kompetenciájával, amelynek fejlesztése szerinte kulcsfontosságú. 
Csépe et al. \cite{magyar3} kutatásában a COVID-19 járvány hatását vizsgálták az egyetemi hallgatók életvitelére vonatkozólag, ahol azt állapították meg, hogy nőtt a nem dohányzók száma, a megkérdezettek közel 20\%-a egészségesebb étrendre tért át, valamint a távolról bejáró hallgatók kiegyensúlyozottabb és egészségesebb alvási szokásokat tudtak felvenni.




%Nemzetközi téren a járvány diákokra gyakorolt hatásáról számos kutatás készült az elmúlt években. Sok helyen kimutatható volt, hogy bár az átlagos tanulmányi teljesítmény nem romlott vagy éppen javult a lezárások idején \cite{student_perf1}, ez gyakran motivációhiánnyal és elidegenedéssel is párosult \cite{student_perf7}, valamint drasztikusan megnőtt a diákokra és szüleikre nehezedő stressz illetve munka mértéke is \cite{student_perf5}. Az új környezetben nyújtott egyetemi teljesítményt nagyban befolyásolta, hogy a hallgatók mennyire  A digitális oktatást hatékonyságát továbbá nehezítette a kiegyenlítetlen elektronikai infrastruktúra, az oktatók elmaradott digitális készségei, hálózati és szoftver elérhetőségi problémák és sok más egyéb tényező is \cite{student_perf4}. A járvány rávilágított a hagyományos oktatási rendszerek sebezhetőségére, ugyanakkor motivációt is adott azok átértékelésére, korszerűsítésére \cite{student_perf8} és új online oktatási módszerek kialakítására egyaránt \cite{student_perf6}.

A pandémia okozta feladatok és problémák megoldásában a gépi tanulási eljárások is fontos szerepet játszottak, legyen szó magáról a járvány terjedésének előrejelzéséről \cite{mlr_1, mlr_2, student_perf4}, vagy az álhírek és tévinformációk beazonosításáról \cite{cov_solution3, cov_solution2, cov_solution}. Természetesen a problémák közé tartozik a diákok/hallgatók teljesítményének és lelki állapotának előrejelzése is, amelynek modellezésére több megoldás is született a járvány kezdete óta. 

Niyogisubizo et al. \cite{modeling1} egy komplex, kétrétegű, hagyományos és mély tanulásos elemeket kombináló osztályozó segítségével értek el 90\% fölötti pontosságot a Nyitrai Konstantin Filozófus Egyetem hallgatóinak lemorzsolódását vizsgálva. Ugyanakkor a modellezésben olyan adatokat is felhasználtak, amelyekről csak a félév közepén kapunk információt. Tarik et al. \cite{modeling3} kutatása során hagyományos modelleket (mint döntési fák és lineáris regresszió) alkalmaztak marokkói hallgatók érettségi átlagának előrejelzéséhez, amely változó hatásfokot mutatott. A predikcióra nézve az egyes változók fontosságát is mérve Segura et al. \cite{modeling2} szintén többnyire hagyományos gépi tanulási algoritmusok segítségével értek el 90\% fölötti eredményeket a spanyol 'Universidad Complutense de Madrid' egyetem hallgatóit vizsgálva lemorzsolódás terén, ahol a kutatás során 28-féle bemeneti változóval és különböző szakirányon tanuló hallgatók adataival dolgoztak. Dake et al. \cite{modeling4} Naive Bayes, véletlen erdő és döntési fa alapú algoritmusokat használtak a teljesítmény előrejelzésére. A kutatás során továbbá megállapították azt is, hogy a pontosság mint mérőszám nem feltétlen elegendő egy osztályozó jóságának eldöntésére. Atlam et al. \cite{student_perf3} vizsgálataik során arab országokban tanuló hallgatóktól gyűjtött, a járvány megélésével és online oktatással kapcsolatos adatokat elemeztek különféle gépi tanulási algoritmusokkal és leíró statisztikai eszközökkel. A gépi tanulás során az egyes kérdésekre adott válaszokból a hallgatók mentális állapotának mint kategorikus változónak a prediktálása volt a cél, ahol a legjobb osztályozók 100\%-os teljesítményt is képesek voltak elérni.

%TODO
%18-as és 20-as cikket belerakni
%esetleg még ezeket: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8744874/
% https://iopscience.iop.org/article/10.1088/1742-6596/1911/1/012008 
%https://www.mdpi.com/2071-1050/12/21/9194/htm
%https://www.mdpi.com/2227-7102/11/7/361/htm

\newpage

\section{Adatprepació}

Az elemzésünkben szereplő bemeneti változók két csoportba oszthatók. Egyik csoportba soroljuk azokat, amelyekkel a diákok már a felvétel pillanatában rendelkeznek, a másikba azokat, amelyek a belépést követően jönnek létre. Az először említett családba tartozik a tanulmányi pontszám, amely adott középiskolai tantárgyak több tanévbeli osztályzatainak összegéből képződik és az általunk vizsgált populációban maximálisan 200 pont lehet, az érettségi eredmény, amely a tantárgyakra kapott jegyekből számítódik és legfeljebb 200 pont lehet, valamint a többletpontok, amelyeket tanulmányi eredményért (emelt érettségi, versenyeredmények) vagy sport- és egyéb területeken elért kiemelkedő teljesítményért, nyelvvizsgáért lehet kapni összesen legfeljebb 100 pont erejéig. Ugyanezen család eleme továbbá, hogy milyen típusú osztályba járt a diák (matematika vagy természettudományi tagozatos, nem tagozatos), hogy emelt vagy középszinten érettségizett-e matematikából, illetve, hogy milyen szakra jár a VBK-n belül.

A belépést követően létrejövő változók családjában két elem szerepel: a 0. zárthelyi dolgozat (továbbiakban 0. ZH) eredménye és a matematikai-nyelvi teszten elért eredmény. Az előbbi teszt egy 45 perces, a középszintű érettségi anyagát számonkérő dolgozat, amely 15 tesztkérdésből áll, ahol minden feladatnál 5 lehetséges válasz közül kell kiválasztani az egyetlen helyeset. Az értékelésnél a hibás válaszokért -1, a helyes válaszért 4 pont jár. Ez egy ún. kritériumdolgozat az általunk vizsgált kar (BME Vegyészmérnöki és Biomérnöki Kar) hallgatói számára. Ez azt jelenti, hogy az első szemeszterbeli kalkulus (Matematika A1a) kurzusnál a vizsgára bocsátás szükséges feltétele a legalább 40\%-os teljesítmény. A dolgozat megíratása papír alapon történik, továbbá minden elsőéves ugyanazt a 0. ZH-t írja meg, függetlenül az érettségi szintjétől és attól, hogy járt-e fakultációra.

A utóbbi teszt egy 80 perces, két nagy egységből (nyelvi és matematikai) álló, a magyar diákok számára szokatlan feladatokat is tartalmazó teszt. A magyar nyelvi feladatsor – hasonlóan a matematikához - nem csak a nyelvi tudást méri, hanem próbára teszi a különböző gondolkodási mechanizmusokat is. A teszt tizenhárom matematikai feleletválasztós kérdést tartalmaz, minden kérdés esetében 4 lehetséges válasszal, amelyek közül egy helyes van. A teszt három részből áll: az első blokk, amely az első négy feladatot foglalja magába az alapvető, procedurális számítási ismereteket ellenőrizi. Ezen feladatok hibátlan, esetleg egy hibával történő megoldása elvárható egy olyan személytől, aki műszaki képzésben kíván egyetemi tanulmányokat folytatni. A második blokk az első blokkhoz képest nehezebb feladatokat tartalmaz. Célja a Matematika A1 kurzushoz szükséges ismeretek meglétének ellenőrzése. Az első blokk feladataihoz képest ebben voltak összetettebb példák, de minden feladat megfogalmazása olyan volt, amellyel már középiskolában is találkozhatott a tesztet író. Ebbe a blokkba 6 feladat tartozik. Az utolsó, harmadik egység olyan szokatlan feladatokat tartalmaz, amelyeket csak a középiskolából származó alapos ismeretekkel rendelkező tanulók tudtak megoldani és azok, akik tudják alkalmazni ezt a tudást miközben váratlan feladatokat oldanak meg. Ezen feladatok megoldásához a legmagasabb szintű absztrakcióra volt szükség. Ez a blokk 4 feladatot tartalmaz. A matematikai-nyelvi teszt matematikai része különböző volt aszerint, hogy a hallgató járt, vagy nem járt fakultációra, hogy mindenkinél a tőle elvárható szint meglétét ellenőrizzük. A nyelvi teszt feladatai viszonylag széles procedurális készségspektrumot fognak be. A nyelvtani elemek ismeretén túl a nyelvi absztrakció több területét érintik. A matematikai-nyelvi teszt elektronikusan, az EduBase online oktatási platformon került kitöltésre.

A bemeneti adatokat az EduBase és Neptun rendszerekből lekérve kaptuk több adattábla formájában. Az ezen adatokból nyert, később használt változók egy része alapvetően rendelkezésünkre állt a táblákból, másokat a meglévő sorokból és oszlopokból megfelelő \textit{feature engineering} segítségével hoztunk létre. A változók modellezésben használt megnevezése és jellege az \ref{tab:valtozok}. táblázatban látható.

\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
Emelt érettségi & \makecell{Bináris változó arra vonatkozóan, hogy \\a hallgató matematikából emelt érettségit tett-e.}\\
\hline
Matematika tagozat & \makecell{Bináris változó arra vonatkozóan, hogy\\ a hallgató matematika és/vagy \\ természettudomány tagozatos volt-e.} \\
\hline
Szak & Kategorikus változó, a hallgató szaka a VBK-n. \\
\hline
Matematika 1. blokk & \makecell{Az elsőéves VBK hallgatók által írt kognitív teszt\\ matematika részén az 1-4. kérdésekre adott \\helyes válaszok száma.} \\
\hline
Matematika 2. blokk & \makecell{A kognitív teszt matematika részén az \\5-10. kérdésekre adott helyes válaszok száma.} \\
\hline
Matematika 3. blokk & \makecell{A kognitív teszt matematika részén a\\11-14. kérdésekre adott helyes válaszok száma.} \\
%\hline
%Matematika eredmény & \makecell{A kognitív teszt matematika részén\\ elért százalékos teljesítmény (0-100-as skálán).} \\
\hline
Kognitív eredmény & \makecell{A matematika-nyelvi teszt nyelvi készségeket mérő részén\\ elért százalékos teljesítmény (0-100-as skálán).}\\
\hline
0. ZH pontszám & A BME központi 0. zárthelyi dolgozatán elért pontszám. \\
\hline
Tanulmányi pont & A felvételi pontszám tanulmányi pontokból származó része. \\
\hline
Érettségi pont & A felvételi pontszám érettségi pontokból származó része. \\
\hline
Többletpont & A felvételi pontszám többletpontokból származó része. \\
\hlineB{5}
Matematika A1a & A Matematika A1a tárgyból szerzett érdemjegy. \\
\hline
Első féléves átlag & Az első félév végén megállapított kumulált átlag. \\
\hline
Kumulált átlag & \makecell{A kutatás idejében aktuális félévig 
megállapított \\ kumulált átlag.} \\
\hline
\end{tabular}
\caption{A vizsgált változók a két évben}
\label{tab:valtozok}
\end{table}

A felderítő és modellezési fázisban használt adattáblát a rendelkezésre álló táblák megfelelő mértékű tisztításából, majd ezt követő Neptun-kód alapú összeillesztéséből nyertük. Ezen műveleteket Python-ban valamint R-ben végeztük el.

A kezdeti adattáblák közül a matematika és nyelvi eredményeket tartalmazó adatsor tisztítására volt a legnagyobb szükség, ugyanis az EduBase rendszerben az egyes oszlopokra vonatozó mezőket a hallgatók töltötték ki, így a kategorikus változók nem voltak rendszerezve. Először egységesítettük a szakmegnevezést ("Vegyészmérnöki", "Biomérnöki", "Környezetmérnöki"), ahol pedig nem volt egyértelmű a szak, azt "UNKNOWN"-ra állítottuk. Ezt követően a teszten elért matematika és kognitív eredményt százalékos formátumról 0-1 közötti tizedestört formátumra változtattuk, valamint létrehoztunk 3 új oszlopot, amely a matematikateszt 3 blokkjában helyesen megválaszolt kérdések számát mutatja. Végül a vizsgálataink szempontjából irreleváns oszlopokat eltávolítottuk, valamint azon oszlopokat is kiszűrtük, amelyek értéke a többiből egyértelműen kikövetkeztethető volt. 

A kumulált átlagokat, felvételi pontszámokat illetve 0. ZH eredményeket tartalmazó tábláknál egy-egy hiányos és/vagy anomáliás sor, illetve az irreleváns oszlopok eltávolításán kívül nem volt szükség adattisztításra, a matematika jegyeket tartalmazó tábla pedig minden hallgató minden Matematika A1a tárgyból tett vizsgaalkalmáról és az azon szerzett érdemjegyről tartalmazott adatrekordot, így ezekből meg kellett határozni azt a végső érdemjegyet, amellyel a hallgató a tárgyat elvégezte. A végső összeillesztés során 10-20 fős sorvesztéssel is kellett számolnunk mindkét évben, ugyanis voltak olyan hallgatók, akikről nem minden táblában volt adat (vagy azért, mert nem írtak kognitív tesztet, vagy azért, mert az első félév vége előtt elhagyták a szakot). Az így kapott adattáblák, amelyek a 2019-es és 2021-es évet reprezentálják, rendre 230 és 202 adatrekordot tartalmaztak, melyekben a vegyészmérnök, biomérnök és környezetmérnök hallgatók száma rendre 119, 81, 28 illetve 104, 71, 21 volt.

A számszerű adatokat legtöbb esetben skálázásnak is alávetettük attribútumonként, amelyhez modelltől és feladattól függően kétféle módszert alkalmaztunk. Az egyik használt módszer a \emph{min-max} skálázás volt, amely az adatokat a [0,1] intervallumra képezi le az alábbi módon:\\
\begin{align}
x_{i}^{'} = \frac{x_{i}-min_{i \in \{1,\dots,n\}}(x_{i})}{max_{i \in \{1,\dots,n\}}(x_{i})-min_{i \in \{1,\dots,n\}}(x_{i})}
\end{align}
ahol az $x_{i}^{'}$ az \emph{i}-edik rekord, $x_i$ értékének a képe. A másik módszer a \emph{kvantilis alapú [0-1] uniform skálázás} volt, amelynél az egyes attribútumok értékeit az általuk meghatározott tapasztalati eloszlásfüggvénybe helyettesítjük be, így az adatok egy [0-1] intervallumon értelmezett uniform eloszlás realizációi lesznek.


\newpage

\section{Felderítő adatelemzés a két évben}

Egy részben feltáró adatelemzés fontos szakasza a felderítő elemzés. Célja az adatok ábrázolása egyszerűen és gyorsan annak érdekében, hogy az adattípusok egyszerű viszonyai szemléletesen áttekinthetőek legyenek. Erre a célra alkalmasak az oszlopdiagramok, szórásdiagramok, folyamatábrák és más grafikonok, továbbá klaszterezéssel kevésbé triviális összefüggések is kinyerhetők az adatból.

\subsection{Általános ábrák}
\label{ssec:altalanos}

Ebben az alfejezetben tekintjük át a számos készült ábrából a leginformatívabbakat. Viszonylag sok változóval kellett dolgozni, így célszerű volt több részábrás egységekbe gyűjteni a hasonló felépítésű grafikonokat. A megfelelő ábrák elkészítéséhez a Python \emph{matplotlib} és \emph{seaborn} csomagjait használtuk. A változók értékeinek eloszlását oszlopdiagramokkal, a változópárok egymás közötti viszonyait szórásdiagramokkal szemléltettük.

Az \ref{tab:valtozok}. táblázatban felsorolt változók közül egyesekből aggregáltunk további két változót. A \emph{Tanulmányi-} és \emph{Érettségi pontot}, illetve a \emph{Többletpontot} összeadva határoztuk meg a \emph{felvételi összpontszámot}. Továbbá a \emph{Matematika 1., 2.} és \emph{3. blokk} értékeit összeadva kaptuk a \emph{matematika összpontot}. Végül használtuk a \emph{teljes teszteredményt}, ami rendelkezésre állt az eredeti adattáblákban, de a \emph{kognitív eredmény} és a \emph{Matematika 1., 2.} és \emph{3. blokk} lineáris kombinációjaként is számolható lett volna.

%A \textit{seaborn pairplot} függvény előnye, hogy csak az általunk vizsgált változók oszlopait kell megadni, és az összes kombinációt egyszerre számítja ki és ábrázolja egy megfelelő méretű mátrixban. Először tekintsük a \textit{matplotlib figure} alakzatokba összesített ábrákat. Ezeknek az az előnye a \textit{seaborn pairplot}-tal szemben, hogy tetszőleges ábrákat lehet belehelyezni, így például színezéssel bevihető egy harmadik dimenzió a szórásdiagramba.


Az \ref{fig:jegyeloszlas}. ábrán a két évben szerzett Matematika A1a -Analízis jegyek eloszlása látható összesítve és szakokra lebontva a két évben. 



\begin{figure}[H] 
\centering
\includegraphics[width=\textwidth]{kepek/jegyek_eloszlas2.png}
\caption{Az elsőéves matematikajegyek eloszlása az egyes években}
\label{fig:jegyeloszlas}
\end{figure} 

\noindent A legszembetűnőbb különbség a két év között az elégtelen, elégséges és közepes érdemjegyek eloszlásának tekintetében van. Az összesített ábrán jól látható, hogy míg 2019-ben a 2-es és 3-as érdmejegyek vannak túlsúlyban, addig 2021-ben az 1-es és 2-es érdemjegyek kerültek többségbe. Ugyanez a jelenség figyelhető meg a biomérnök és környezetmérnök hallgatók esetén is.

A \ref{fig:2019scatter}. és \ref{fig:2021scatter}. ábrán a 0. ZH, a teszt összpontszáma és a két külön rész pontszámai vannak ábrázolva pontfelhőként a felvételi összpontszám függvényében a két évben, minden esetben kétszer. A felső sorban a pontok az alapján vannak színezve, hogy járt-e természettudományi tagozatra a hallgató (1 igen, 0 nem), az alsóban pedig, hogy emelt szinten érettségizett-e (1 igen, 0 nem).

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{kepek/2019scatter.png}
\caption{2019-es adatok szórásdiagramjai}
\label{fig:2019scatter}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{kepek/2021scatter.png}
\caption{2021-es adatok szórásdiagramjai}
\label{fig:2021scatter}
\end{figure}

A 2019-es ábrán egyrészt az látszik, hogy minden részábrán a bal felső és a jobb alsó sarkokban többnyire nincs pont, ez a pozitív korreláció jele. Másrészt a színezésből arra következtethetünk, hogy az emelt érettségi megléte (amelyért ráadásul 50 többletpont jár, ha a diák 40\%-nál jobb eredményt ér el) és a magas felvételi pontszám további kimagasló eredményekkel társul, kivéve a teszt nyelvi részénél, ott jobban megoszlanak az eredmények. Ezzel szemben a természettudományi tagozatoknak nincs látható hatása a további eredményekre, ugyanis a sárga pontok szét vannak szóródva az egész pontfelhőre minden esetben.

A 2021-es ábráról az állapítható meg, hogy a 2019-es ábrához képest nőtt a változók szórása, ugyanis a pontfelhők jobban szétterülnek. Ennek a hátterében állhatnak a vírushelyzet okozta nehézségek és az adott években bevezetett távolléti oktatás. A természettudományi tagozaton való tanulás továbbra sem fejtett ki hatást a többi eredményre. Az emelt szintű érettségi meglétének hatása viszont 2019-hez képest csökkent, ez a teljes teszteredménynél a legszemléletesebb.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{kepek/2019minmax3.png}
\caption{2019. Teszt és felvételi pontszám részei}
\label{fig:2019minmax3}
\end{figure}

A \ref{fig:2019minmax3}. ábrán látható a \textit{seaborn pairplot} függvény egyik eredménye. Ebben az esetben volt két hallgató, aki pont duplázással számította a teljes felvételi pontszámát, így a hozott pontszámánál 0 állt értékként. Ez természetesen torzítást okozott a megfelelő részábrákon, így ki lettek véve. A változók itt min-max skálázva vannak, így minden tengelyen 0-tól 1-ig vannak értékek.

A többletpontot tartalmazó részábráktól és az oszlopdiagramoktól eltekintve, a többi részábrán a pontfelhők gyenge pozitív korrelációt mutatnak, de az adatok szórása minden dimenzióban egészen nagy. Érdekes, hogy a kognitív eredmény oszlopdiagramja a normális eloszlás haranggörbéjéhez közelít annak ellenére, hogy a felvételi pontszám részeinek eseteiben a jó eredmények dominálnak.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{kepek/2021minmax3.png}
\caption{2021. Teszt és felvételi pontszám részei}
\label{fig:2021minmax3}
\end{figure}

Az \ref{fig:2021minmax3}. ábrán egészen hasonló képet látunk, mint a 2019 esetében (\ref{fig:2019minmax3}. ábra), de itt ismét erősebb a szórás. Továbbá szembetűnő az érettségi pontszámok eloszlásának megváltozása. Míg 2019-ben a skálázott adatok nagy része 0.5-1 között van, 2021-ben már az egész intervallumra széthúzódnak. 

Eddig a pontfelhők nem mutatnak erős korrelációt, illetve a kétdimenziós vetületekben nem emelkednek ki csoportok. Más változókat is vizsgáltunk, a róluk készült ábrák alább tekinthetők meg.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{kepek/2019minmax4.png}
\caption{2019. Teszt részek, átlagok és felvételi összpontszám}
\label{fig:2019minmax4}
\end{figure}

A \ref{fig:2019minmax4}. ábrán a felvételi pontszám össze lett vonva és be lett véve az első féléves és a későbbi kumulált átlag. Nyilván az utóbbi kettő erősen összefügg. Enyhén kirajzolódik egy összefüggés a felvételi pontszám és az átlag között. Érdekes, hogy a kumulált átlag eloszlása jobban közelít a normális eloszláshoz, mint az első féléves átlagé, ami eltolódik a skála alja felé.


\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{kepek/2021minmax.png}
\caption{2021. Teszt részek, átlag és felvételi összpontszám}
\label{fig:2021minmax}
\end{figure}

A \ref{fig:2021minmax}. ábra esetében nem volt értelme a kumulált átlagot bevenni, ugyanis a kutatás idejében megegyezett az első féléves átlaggal. Itt is megmaradt a felvételi összpontszám és az átlag közötti összefüggés, de a pontfelhő kevésbé zajos. A matematikai rész pontszáma és az átlag között is van gyenge, pozitív összefüggés.



\subsection{Folyamatábrák (Sankey-diagramok)}
A Sankey-diagramok olyan folyamatábrák, amelyekben az ábrázolt folyamok szélessége arányos a megfelelő folyamértékekkel. Ezáltal könnyen ábrázolhatóak adott állapotok közötti folyamok, illetve ezek egymással vett aránya. Egy hátránya van, hogy egy ábrán csak két osztálycsoport között olvashatjuk le az áramlásokat. Ha egy harmadik osztálycsoportot is belehelyezünk, és csak a másodikkal kötjük össze, akkor az első és a harmadik közötti vándorlások nem jelennek meg rajta. Emiatt van némi redundancia a lentebb ismertetett ábrákban.\\
Dolgozatunkban hat opciót vizsgáltunk a két évben az elérhető adatoknak megfelelően. Mindkét esetben az állapotok a hallgatók valamely eredményét jelentették, például felvételi pontszámot.

\begin{itemize}

\item 2019:

\begin{enumerate}
\item matematikai teszt 1.,2. és 3. blokkjaiban helyesen megoldott feladatok száma.
\item teljes teszteredmény - \textit{A1} jegy - \textit{A2} jegy.
\end{enumerate}

\item 2019 és 2021:

\begin{enumerate}
\item tanulmányi pont - érettségi pont - \textit{A1} jegy.
\item felvételi összpontszám - 0. ZH - teljes teszteredmény.
\item felvételi összpontszám - teljes teszteredmény - \textit{A1} jegy - kumulált átlag.
\item felvételi összpontszám - teljes teszteredmény - első féléves átlag - kumulált átlag.
\end{enumerate}

\end{itemize}

Az első két esetben csak a 2019-es évfolyamról volt adat. Az utolsó esetben 2021-ben megegyezett a kutatás idejében az első féléves és a kumulált átlag, így ennél az utóbbi értelemszerűen nem lett még egyszer beletéve.

A matematikai teszt részeinek eredményein és az \textit{A1}, \textit{A2} jegyeken kívül a többi változó folytonos volt, így szükség volt ezek diszkretizálására. Öt-öt osztály lett létrehozva minden esetben, de nem feltétlenül került mindegyikbe hallgató. Az átlagok kerekítve lettek, a felvételi összpontszám, teljes teszteredmény és a 0. ZH pontszámok ekvidisztáns módon lettek felosztva.

A \textit{felvételi összpontszám - 0. ZH - teljes teszteredmény} változatban a 0. ZH és a teszt eredményei nullától az elérhető pontszámig lettek felosztva 20\%-os lépésközökkel. A felvételi összpontszám a legalacsonyabb értéktől 500 pontig. A többi változat a kutatás későbbi szakaszában készült, így a folytonos mutatók az értékkészletük terjedelme szerint lettek felosztva, nem az elérhető pontszámok alapján. Végül a kirajzolódott ábrákat kézileg még igazítani kellett, ugyanis az eredmények csoportjai nem feltétlenül álltak megfelelő sorrendben a függőleges tengelyen, illetve azokban az esetekben, amikor nem volt mind az öt osztályban hallgató, egy-egy csoport átcsúszott egy másik eredmény oszlopába. Ezek azonban nem okoztak gondot, ugyanis a csoport mozgatásával a hozzátartozó sávok is automatikusan együtt mozogtak.

%EZEK SZERINTEM NEM KELLENEK

%Ezután \textit{for ciklus} használatával elkészültek a tranzíciós mátrixok. Ezen mátrixok \textit{i}-edik sorának \textit{j}-edik eleme azt mutatta, hogy az egyik változó \textit{i}-edik osztályában hány olyan hallgató volt, aki a másik változó \textit{j}-edik osztályába került. Ez a folyamok szélességének megadásához volt szükséges.

%A \textit{plotly.graph\_objects} könyvtár \textit{go.Sankey} függvényével lettek elkészítve egyenként az ábrák. Minden esetben meg kellett adni számozva a kiinduló és beérkező állapotokat, így a középső csoportok mindkét listában szerepeltek. A program index alapján kapcsolta össze a két listából az állapotokat, továbbá kellett egy harmadik lista, amelynek a megfelelő indexű eleme a két állapot közötti folyam mérete. Ezen kívül a folyamokhoz és magukhoz az állapotokhoz is színeket kellett még rendelni, ismét egy-egy listában, figyelve az indexeket. 



%IDE BE KELL ILLESZTENI A teszt-a1-a2 ábrát
\begin{figure}[H]
\centering
\includegraphics[width = \textwidth]{kepek/teszt-a1-a2.png}
\caption{2019. teljes teszteredmény - \textit{A1} jegy - \textit{A2} jegy}
\label{fig:teszt-a1-a2}
\end{figure}

A \ref{fig:teszt-a1-a2}. ábrán rögtön látható, hogy a kognitív tesztben mindenki 20\% felett teljesített, de nagyon kevés hallgatónak sikerült 80\%-nál magasabb eredményt elérni. Ehhez képest az tantárgyakon elért jegyek eloszlása egyenletesebb. 

Látható, hogy akik a teszten gyengébben teljesítettek, azok a későbbiekben többnyire rosszabb jegyeket szereztek, de nem kevesen javítottak is. A jobban teljesítők szintén tartották általában a szintet, de itt sem elhanyagolható azok száma, aki rontott. Meglepő a kettesről négyes-ötösre javítók és az ötösről rosszabb jegyekre rontó hallgatók aránya a teljes viszonylatban.

Összességében az figyelhető meg, hogy míg az első két változó közötti átmenet viszonylag egységes, a két tárgy közötti átmenetek nagyon változatosak. Ez azt jelenti, hogy a bemeneti teljesítmény részben befolyásolja az első néhány eredményt, de a későbbiekbe már kevesebb beleszólása van.

A 2021-es gólyák a kutatás idejében még nem vehették fel az \textit{A2} tárgyat, így értelemszerűen csak a 2019-es évfolyamra készült ilyen ábra.

\begin{figure}[H]
\centering
\includegraphics[scale=0.573]{kepek/matekrészeksankey.png}
\caption{2019. Matematikai teszt 1. blokk - 2. blokk - 3. blokk helyes válaszainak száma}
\label{fig:matekrészeksankey}
\end{figure}

A teszt matematikai részének a komplexitása a blokkonként nőtt, így érdekes volt megvizsgálni, hogyan teljesítettek a hallgatók, és hogyan viszonyul egymáshoz a helyes válaszaik száma a különböző blokkokban.

A \ref{fig:matekrészeksankey}. ábrán rögtön látszik, hogy az első blokkban a hibátlan (négyes) osztály a legnagyobb, és a rosszabb eredmények száma csökken. Ez várható, hiszen itt alapismeretek voltak felmérve. A második és harmadik blokknál teljesen más a kép, a közepes osztályok körülbelül azonosak, a szélsők pedig kicsik, jobban hasonlít a normális eloszlásra.

A folyamok egészen változatosak. Az ábra közepén erősen szétoszlanak, de a széleihez közelítve kisebb trendek megfigyelhetők. Például a második blokkban minden kérdésre helyesen válaszolt hallgatók az első blokkban is többnyire szinte csak helyesen válaszoltak.

%IDE BE KELL ILLESZTENI A 2019_old_felvi_0zh_teszt ábrát
\begin{figure}[H]
\centering
\includegraphics[scale=0.573]{kepek/2019_old_felvi_0zh_teszt.png}
\caption{2019. Felvételi összpontszám - 0. ZH - teljes teszteredmény}
\label{fig:2019_old_felvi_0zh_teszt}
\end{figure}

A \ref{fig:2019_old_felvi_0zh_teszt}. ábrán főleg a 0. ZH-ból a tesztbe menő folyamokon látszik egy erős tendencia. Igaz itt még a régebbi, teljes szerezhető pontszám szerinti felosztás van, így csak négy osztály jött létre, de nagyon kevés többosztálynyi ugrás van, tehát feltehető, hogy erősen összefügg a 0. ZH és a teljes teszteredmény.

Ami a felvételi és 0. ZH pontszámok kapcsolatait illeti, a folyamok egészen szerteágazóak, de itt is fennáll, hogy a közel hasonló teljesítmények között szélesebbek, mint a nagyobb különbségek esetén.

\begin{figure}[H]
\centering
\includegraphics[scale=0.573]{kepek/2021_old_felvi_0zh_teszt.png}
\caption{2021. Felvételi összpontszám - 0. ZH - teljes teszteredmény}
\label{fig:2021_old_felvi_0zh_teszt}
\end{figure}

Annak ellenére, hogy a tesztes oszlop a 2019-es tesztes oszlopra hasonlít, csak fejjel lefelé, ez a valós eloszlás. Valóban, míg 2019-ben nem volt 20\% alatti eredmény, itt fordítva, nem volt 80\% fölötti. A felvételi pontszámok arányai romlottak, arányosan nagyobbak lettek az alsó osztályok. Ellenkezőleg, a 0. ZH eredményei javultak, nagyobbak a magasabb pontszámhoz tartozó osztályok arányai. 

Ami a folyamokat illeti, többnyire hasonlóak a tendenciák, bár érdekes, hogy akiknek a legrosszabb lett a 0. ZH, a kognitív teszt közepesen ment. Itt is mondható, hogy a jobban teljesítő hallgatók többnyire mindenből jól teljesítettek, illetve a gyengébbek között ritkábbak voltak a jobb eredmények. Ennek ellenére itt is szerteágazóak a folyamok, tehát összefüggés van, de nem nagyon erős.


\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{kepek/2019_felvi_teszt_atlag_kumatlag.png}
\caption{2019. Felvételi összpontszám - teljes teszteredmény - első féléves átlag - kumulált átlag}
\label{fig:2019_felvi_teszt_atlag_kumatlag}
\end{figure}

A \ref{fig:2019_felvi_teszt_atlag_kumatlag}. ábrán már közvetlenül láthatóak a felvételi és kognitív teszt eredményeinek viszonyai, azonban itt már az értékkészlet van felosztva ekvidisztánsan. Ez abban is megnyilvánul, hogy a teszt pontszámosztályainak mások az arányai. 

Két előnye volt az értékkészlet szerinti osztályozásnak: gyorsabb volt (egy függvényre volt csak szükség), illetve így az eredmények egymáshoz képest való relatív eloszlása jobban látszik. Míg a régebbi ábrákon nagyon nagy a hármas osztály, mert a legtöbben 40-60\% körüli eredményeket értek el, itt az látszik, hogy a legjobb és legrosszabb dolgozatok pontszámai között, a terjedelem 20\%-ával lépkedve milyen a hallgatók eloszlása. Így az lesz valóban "középtájban", aki a többi hallgató pontszámához képest átlaghoz közeli pontszámot szerzett, nem pedig az a sok tanuló, aki 40-60\%-ot ért el.

Visszatérve a \ref{fig:2019_felvi_teszt_atlag_kumatlag}. ábrára, a fentebb megfigyelt tendenciák lényegében ismétlődnek, jó eredményeket jók, rosszakat rosszak követik nagyrészt, de továbbra is változatosak a folyamok. Összefüggőség szempontjából jó jel, hogy a legjobb teszteredményt elérők négyesnél rosszabb átlagot nem értek el. Sőt nagyon sok hallgatónak volt négyes az átlaga az első félévben, ami nagyrészt kétfelé oszlott az idő elteltével, többen megtartották, de sokan rontottak hármasra, páran javítottak. A többi átlagértékkel hasonló a helyzet, inkább megmaradt, mint javult vagy romlott.

%IDE BE KELL ILLESZTENI A 2021_felvi_teszt_atlag ábrát

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{kepek/2021_felvi_teszt_atlag.png}
\caption{2021. Felvételi összpontszám - teljes teszteredmény - első féléves átlag}
\label{fig:2021_felvi_teszt_atlag}
\end{figure}

A kutatás idejében ez az évfolyam még az első évében volt, így csak első féléves átlagokról volt adatunk. Ettől eltekintve, a \ref{fig:2021_felvi_teszt_atlag}. ábrán látszik, hogy 2019-hez képest több hallgatónak volt relatíve gyengébb a felvételi pontszáma, de ennek megfelelően többen is "javítottak". Az átlagok eloszlása romlott, aránylag több hármas és kevesebb négyes, illetve ötös lett. 

%IDE BE KELL ILLESZTENI A 2019_felvi_teszt_a1_kumatl ábrát
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{kepek/2019_felvi_teszt_a1_kumatl.png}
\caption{2019. Felvételi összpontszám - teljes teszteredmény- \textit{A1} jegy - kumulált átlag}
\label{fig:2019_felvi_teszt_a1_kumatl}
\end{figure}

A \ref{fig:2019_felvi_teszt_a1_kumatl}. ábra első két oszlopának viszonyát már láttuk, az újdonság az \textit{A1} jegy az első féléves átlag helyett. Ettől függetlenül a tendenciák változatlanok, azok szereztek jobb, illetve rosszabb jegyet, akik rendszerint jobban, illetve rosszabban írták meg a tesztet. A trendet továbbra erősíti a jegyek és átlagok viszonya, bár értelemszerűen nem meglepő, hogy a két dolog összefügg.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{kepek/2021_felvi_teszt_a1_atlag.png}
\caption{2021. Felvételi összpontszám - teljes teszteredmény - \textit{A1} jegy - első féléves átlag}
\label{fig:2021_felvi_teszt_a1_atlag}
\end{figure}

A \ref{fig:2021_felvi_teszt_a1_atlag}. ábrán szembetűnő, hogy az \textit{A1} jegyek valamilyen okból kifolyólag erősen romlottak. Míg 2019-ben nem bukott egy hallgató sem, itt majdnem a csoport negyedének nem sikerült elvégezni a tárgyat, sőt olyanoknak is, akik a legjobbak között voltak a teszt alapján. Továbbá a csoportnak több, mint a fele nem tudott kettesnél jobb jegyet szerezni. Fentebb láttuk, hogy az átlagok is romlottak, de ezek szerint nem olyan mértékben, mint az \textit{A1} jegyek. Érdekes, hogy az egyest és kettest szerzett hallgatók mégis nagyrészt hármas, sőt nem kevesen négyes átlagot szereztek. Ettől függetlenül a szokásos trendek itt is megmutatkoznak.
 
%IDE BE KELL ILLESZTENI A 2019_hozott_erett_A1 ábrát
\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{kepek/2019_hozott_erett_A1.png}
\caption{2019. tanulmányi pont - érettségi pont - \textit{A1} jegy}
\label{fig:2019_hozott_erett_A1}
\end{figure}
Ahogy később látni fogjuk, a modellek alapján a tanulmányi és érettségi pontszámok erősen befolyásolták a jegyekre vett predikciókat, így utólag elkészült a \ref{fig:2019_hozott_erett_A1}. és a \ref{fig:2021_hozott_erett_A1}. ábra.

Jellegzetes, hogy a hallgatók nagy részének hasonló volt a tanulmányi pontszáma, nagyon kevésnek volt kiemelkedő vagy relatíve kicsi. Aránylag kevés hallgatónak volt a legjobb pontszám 60\%-a alatt az érettségije. Még ezek mellett is megőrződött az a tendencia, hogy egy-egy hallgató nagyrészt hasonlóan teljesít a különböző mutatók alapján.

Az ábráról leolvasható, hogy míg az utolsó oszlop felső felébe szinte csak kék és zöld folyamok érkeznek, mégis szerteágaznak, és például a legjobb érettségi pontszámokkal rendelkezők közül is többen kettest szereztek a tárgyból. 

%IDE BE KELL ILLESZTENI A 2021_hozott_erett_A1 ábrát
\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{kepek/2021_hozott_erett_A1.png}
\caption{2021. tanulmányi pont - érettségi pont - \textit{A1} jegy}
\label{fig:2021_hozott_erett_A1}
\end{figure}

A \ref{fig:2021_hozott_erett_A1} ábrán rögtön szembetűnik egy meglepő dolog, a tanulmányi pontszámoknál van egy óriási ötös osztály. Az értékeket leellenőrízve, tényleg nagyon sok esetben 180 és 190 között mozgott a hozott pontszám.

Ehhez (és a \ref{fig:2019_hozott_erett_A1}. ábrához) képest, az érettségi pontszám viszont egészen egyenletesen oszlott el. Az ábra bal felétől eltekintve, a teljesítmény megmaradására vonatkozó tendencia gyengébben, de ismét jelen van.


\subsection{Klaszterezés}

A klaszterezés célja általában esetleges nem triviális összefüggések feltárása, illetve az adatok csoportokba való sorolása gépi tanulási módszerekkel úgy, hogy az azonos csoportban lévő adatok "hasonlóbbak" legyenek egymás közt, mint a különböző csoportokból vett adatok.

Egyes esetekben a klaszterezés eredménye rámutathat néhány változóra, amelyeknek erős a magyarázóereje, így a további vizsgálatokból el lehet hagyni a többi változót. Ennek ellenére gyakoriak azok az esetek, amikor nehéz vagy nem lehet megállapítani ezeket a változókat, mert minden változó fontos. Ilyenkor az adatok két-három dimenziós vetületeinek szórásdiagramjai többnyire homogének és nem csoportosíthatóak szemre.

A \ref{ssec:altalanos}. alfejezetben szereplő ábrákat áttekintve, első ránézésre nem rajzolódott ki olyan kétdimenziós vetület, amelyben láthatóan megjelennének csoportok. Ennek ellenére három gépi tanulási módszer lett kipróbálva:
\begin{enumerate}
\item K-közép algoritmus
\item DBSCAN algoritmus
\item Ward-féle hierarchikus klaszterező algoritmus.
\end{enumerate}

Számos optimalizációs kísérlet volt: hiperparaméterek beállítása, változók válogatása, illetve többféle skálázás. Volt egy kísérlet PCA alkalmazására, azonban minden esetben csak az összes megadott változó reprezentálta eléggé jól az adatot, így ez el lett vetve. Sok modell és klaszterkép készült, a legérdekesebbek lentebb lesznek bemutatva. A szemléltetéshez a bevett változók közötti páros szórásdiagramok lettek legenerálva és a pontok az alapján lettek színezve, amely klaszterbe kerültek.

\subsubsection{K-közép algoritmus működése}
Az algoritmus működési elve nagyon egyszerű. Az alapvető paraméter, amelyet meg kell adni, a létrehozandó osztályok kívánt száma, legyen ez \textit{k}. Első lépésben választ a térben véletlenszerűen \textit{k} pontot, ezek a klaszter középpontok, majd az összes pontot ahhoz a a középponthoz rendeli, amelyhez a legközelebb van. A második lépésben a kialakult osztályok középpontjait újraszámolja és azokkal a középpontokkal megismétli az első lépést. Ezt a két lépést iterálja addig, amíg két egymást követő osztályozás között már nem lesz jelentős változás.

Így alapvetően a legfontosabb feladat a megfelelő klaszterszám meghatározása. Ehhez létezik egy könyökszabály, melynek a lényege a következő: lefuttatjuk a klaszterezési algoritmust 1-től $l$-ig ($l$ egy tetszőlegesen választott szám) megadva a klaszterszámokat, majd ábrázoljuk ezek esetében a pontoknak az átlagos négyzetes eltérését a saját klaszterközéppontjuktól. Természetesen ahogy több csoportra bontjuk a pontokat, úgy csökken ez az eltérés, így az a klaszterszám lesz optimális, ahol jelentős a javulás, de utána már nem. Ez megfelelő esetben vizuálisan egy behajlított karra emlékeztet, innen ered a neve. Nehezen klaszterezhető adatok esetén ez a görbe "simább", nehezen állapítható meg a "könyök".

\subsubsection{DBSCAN algoritmus működése}

A DBSCAN (Density-based spatial clustering of applications with noise) sűrűség alapú klaszterező algoritmus \cite{bevadat}. Ebben az esetben a sűrűség egy bizonyos $\epsilon$ sugáron belüli pontok száma. Ez alapján az algoritmus három kategóriára osztja az adatpontokat:
\begin{itemize}
\item Magpont: olyan adatpont, melynek egy meghatározott számúnál ($\mu$) több pont van az $\epsilon$ sugarú környezetében.
\item Határpont: olyan adatpont, amelynek $\mu$ -nél kevesebb pont van az $\epsilon$ sugarú környezetében, de ő maga egy magpont $\epsilon$ sugarú környezetébe esik.
\item Zaj (outlier): olyan adatpont, amely egyike sem az előzőknek.
\end{itemize}

Működése során először felosztja az adatpontokat a három leírt típus szerint, majd a zajos pontokat figyelmen kívül hagyja. A többi pont esetén a sűrűn összefüggő részek határozzák meg a klasztereket. Előnye, hogy kiszűri a zajos pontokat és érzéketlen rájuk, illetve jól kezeli a különböző méretű osztályokat. Változó sűrűségű csoportok esetén gyengébben teljesít.

A felhasználó feladata meghatározni a $\mu$ és $\epsilon$ értékeket, illetve a megfelelő távolságfogalmat. Ehhez szintén létezik egy könyökszabály. Ennél az algoritmusnál növekvő sorrendben kell ábrázolni az egyes adatpontoknak a legközelebbi szomszédjuktól vett távolságot. Mivel sok adatpont van, a könyök simább, így az $\epsilon$-t csak becsülni tudjuk. 

Ezután a $\mu$ paramétert kell hozzáigazítani oly módon, hogy a kialakuló klaszterszám megfelelő legyen. Ez úgy történik, hogy az adott paraméterpárral lefuttatjuk az algoritmust és megnézzük a keletkezett klaszterek számát. Azt a párt választjuk, aminél megfelelő a klaszterszám.

\subsubsection{Ward-féle hierarchikus klaszterező algoritmus működése}

Az általunk használt hierarchikus klaszterező algoritmus agglomeratív módon hozza létre a klasztereket. Azaz először minden pontot külön klaszternek tekint, majd ezeket egyesíti egy kiválasztott módszer alapján addig, amíg az összes pont egy klaszterbe nem kerül. Az iterációkat dendrogrammal lehet ábrázolni, és az alapján lehet dönteni, hány klasztert akarunk létrehozni. Gyakorlatban a dendrogramon meg kell keresni a legszélesebb vízszintes sávot, amelyben csak függőleges szakaszok vannak, és venni azok számát.

Az alapvető egyesítő módszerek a single, average, complete linkage nevet hordozzák, de mi a Ward-féle módszert alkalmaztuk. Ez a módszer az összes klaszteren belüli szórásnégyzet minimalizálására törekszik, így valamelyest hasonlít a K-közép algoritmusra.

\subsubsection{K-közép algoritmus eredménye}
Ami a szórásdiagramokból sejthető volt, a könyökszabály alkalmazása során igazolódott be. Szinte minden próbálkozás esetén sima volt a görbe, és nem volt egyértelműen jó klaszterezés. Ezekben az esetekben a klaszterkép is elmosott volt.

A K-közép algoritmus eredményei közül kettőt emelhetünk ki. Az egyikben a 2019-es adatokból négy változó szerepelt, min-max skálázva: teljes teszteredmény, első féléves átlag, kumulált átlag és a felvételi összpontszám. A másikban ugyanez a felállás 2021-re, kivéve a kumulált átlagot, mert az megegyezett az első félévessel. Az első változatnak a könyökszabály ábrája tekinthető meg alább:

\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{kepek/2019_kmeans_best_konyok.png}
\caption{2019. K-közép, 4 változós könyökszabály}
\label{fig:2019_kmeans_best_konyok}
\end{figure}

Természetesen ezen az ábrán (\ref{fig:2019_kmeans_best_konyok}.) sincs teljesen egyértelmű törés, de 5 klaszter esetén mondható közel optimálisnak. Ezzel az alábbi klaszterképet generálta az algoritmus:

\begin{figure}[H]
\centering
\includegraphics[width = \textwidth]{kepek/2019_kmeans_5.png}
\caption{2019. K-közép, 4 változós klaszterkép}
\label{fig:2019_kmeans_5}
\end{figure}

A \ref{fig:2019_kmeans_5}. ábrán lévő részábrák közül a legtisztábban a felvételi összpontszám és az első féléves átlag szórásdiagramján látszanak az osztályhatárok. Megfigyelhető az algoritmus jellegzetessége, a hasonló méretű, "gömbszerű" klaszterek kialakítása. A kékes zöld klaszter a legstabilabb, annak az adatpontjai mindig a jobb felső sarokban vannak, azaz minden változóban magas értékeik vannak. A lila hasonlóan viselkedik, csak mérsékeltebb, minden változóban átlag felettiek, de nem a legjobbak. Ezzel szemben a zöld klaszter azokból a hallgatókból áll, akik átlagosan teljesítettek a felvételi és a teszt során, de más mutatókban lecsúsztak. A kék a legbizonytalanabb, ugyanis többnyire középütt van mindig, de mélyen belemetsz más klaszterokba. A sárga klaszter pontjai minden változó esetén a skála alsó felén vannak, kivéve a kumulált átlagot, ahol középtájt összpontosulnak.

\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{kepek/2021_kmeans_konyok.png}
\caption{2021. K-közép, 3 változós könyökszabály}
\label{fig:2021_kmeans_konyok}
\end{figure}

Ezen az ábrán (\ref{fig:2021_kmeans_konyok}.) a könyök jobb a \ref{fig:2019_kmeans_best_konyok}. ábrán lévő könyöknél, ugyanis 3-nál még érzékeny a törés, de utána szinte kisimul.

\begin{figure}[H]
\centering
\includegraphics[width = \textwidth]{kepek/2021klacter.png}
\caption{2021. K-közép, 3 változós klaszterkép}
\label{fig:2021klacter}
\end{figure}

Ebben az esetben (\ref{fig:2021klacter}. ábra) még tisztább az elkülönülés az első féléves átlag és a felvételi összpontszám esetén, tehát feltehetőleg ezek jobban befolyásolták a döntést. Itt is gömbszerű klaszterek lettek, ugyanis a pontfelhő egészen homogén.

\subsubsection{DBSCAN eredménye}

A DBSCAN algoritmus akkor működik igazán jól, ha az adatok pontfelhője közel azonos sűrűségű részekből áll, amelyek között nagyobb távolság van. Az elkészített, és fentebb bemutatott ábrákon (\ref{ssec:altalanos}) nem volt jellemző az előbb említett tulajdonság. Ennek következményeként az algoritmussal nem sikerült jó klaszterezést megvalósítani.

A futtatások során az eredmények két csoportba voltak kategorizálhatóak. Az egyikben létrejött egy nagy klaszter és elenyésző volt a többi, a másikban a pontok nagy része "outlier" volt és néhány nagyobb, de továbbra is kis méretű klaszter jelent meg. Egy ilyet tekinthetünk meg alább.

\begin{figure}[H]
\centering
\includegraphics[width = \textwidth]{kepek/dbscan2.png}
\caption{2019. DBSCAN, 4 változós klaszterkép}
\label{fig:dbscan2}
\end{figure}

A \ref{fig:dbscan2}. ábrán lévő klaszterezés 2019-es adatokon készült, Mahalanobis távolságot használva és kvantilisek mentén skálázva. Ismét ugyanaz a négy változó került be: teljes teszteredmény, első féléves átlag, kumulált átlag és a felvételi összpontszám. Látszik, hogy piros pontokból van a legtöbb, amelyekhez a -1-edik klasztert rendelte az algoritmus, ezek az outlierek. A zöld és a kék klaszter még viszonylag nagy, de a többi csak pár pontot tartalmaz.

\subsubsection{Ward-féle algoritmus eredménye}

Mint ahogy a másik két módszernél a könyökszabályokban, itt a dendrogramokban volt nehéz eldönteni az optimális paraméter értéket, jelen esetben a klaszterszámot. Ha egy szám optimális, akkor az a síkrész, amelyben annyi függőleges vonal megy, kiemelkedően széles. Ha nehezen klaszterezhető az adat, akkor kisebbek a sávok, és azok közül a legnagyobbak közel azonos méretűek. Ezt lehet látni az alábbi, \ref{fig:dendrogram}. ábrán:

\begin{figure}[H]
\centering
\includegraphics[width = \textwidth]{kepek/dendrogram.png}
\caption{Dendrogram}
\label{fig:dendrogram}
\end{figure}

Itt a kettő és a három függőleges szálat tartalmazó sávok szélessége közel azonos. A választás három klaszterre esett. Kevesebb változó választásánál a klaszterek száma minden esetben legfeljebb kettő esetén lett volna optimális, így egészen sokat kellett használni: \textit{matematika összpont, kognitív eredmény, kumulált átlag, tanulmányi pont, érettségi pont, többletpont}.

\begin{figure}[H]
\centering
\includegraphics[scale = 0.57]{kepek/klacterward.png}
\caption{Ward féle algoritmus eredménye}
\label{fig:klacterward}
\end{figure}

A változók nagy száma miatt lett ilyen nagy a párosításos ábra (\ref{fig:klacterward}.). Mindez a 2019-es adatokból van, kvantilisek mentén skálázva. Minden erőfeszítés ellenére nem alakult ki tisztább klaszterkép. Itt is a K-középhez hasonlóan a három klaszter a "jók", "közepesek" és a "gyengébbek" osztályait jelenti, de nincs vetület, amin olyan sima lenne a klaszterhatár.

\section{Konklúziók a feltáró adatelemzésből}

A fejezetben ismertetett szórásdiagramok adtak egy szemléletes képet az adatok egyszerű viszonyairól. Többnyire látszott, hogy a változók között pozitív korreláció volt, de nem kimondottan erős. Ez motivációt adott az adatok további, mélyebb és komplexebb vizsgálatához annak érdekében, hogy felfedezhetőek legyenek nem triviális kapcsolatok. Továbbá az ábrák összehasonlítása kimutatott egy jelentős különbséget a két év eredményei között, ami szintén indokolja a további elemzést. Szem előtt kell tartani, hogy 2021-ben a diákok már részt vettek távolléti oktatásban, és ez feltehetőleg a változások kiváltó oka lehetett.

A folyamatábrák vizsgálata fényt derített több érdekességre. Például a \ref{fig:teszt-a1-a2}. ábrából azt a következtetést vonhattuk le, hogy míg a bemeneti eredmények viszonylag erősen befolyásolták az első néhány megmérettetés eredményét, a további eredmények már nagyobb részben nem függtek tőlük. Ez az $A1$ és $A2$ tárgyak közötti átmenetek alapján látszik tisztán. Ez kívánt eredmény, ugyanis az egyetem szerepe nem lenne jelentős, ha csak a felvételi eredményeken múlna a további sikeresség.

A Sankey-diagramok szintén fényt derítettek a két év eredményességeinek különbségére. Ennek a leglátványosabb példája a \ref{fig:2019_hozott_erett_A1}. és \ref{fig:2021_hozott_erett_A1}. ábra, ahol a tanulmányi pontok eloszlásai között óriási különbség van. A két évben az $A1$ jegyek eloszlási között is érdemi a különbség, de az elvárásokkal szemben 2021-ben romlottak. Ennek több oka lehet, többek közt a tárgykövetelmény szigorítása.

Összességben a folyamatábrákból az a következmény vonható le, hogy a bemeneti eredményeknek van hatása a továbbhaladásra, de idővel gyengül. Továbbá a változók értékkészletének két szélén lévő hallgatók eredményei könnyebben követhetők, míg a közepes hallgatók esetében nagyobbak a fluktuációk.

A szórásdiagramok eredményeinek elemzése alapján a klaszterezéstől nagy áttörés nehezen volt elvárható. A további kísérletek során bebizonyosodott, hogy a birtokunkban lévő adatok nehezen klaszterezhetőek. Ennek ellenére a K-közép algoritmussal sikerült elérni egészen tiszta klaszterhatárokat, és azt figyeltük meg, hogy ezek az első féléves átlag és a felvételi összpontszám esetében voltak a legtisztábbak. A DBSCAN algoritmushoz egyáltalán nem volt megfelelő az adat, a Ward-féle módszer szintén gyengébben teljesített a K-középnél.




\newpage
\section{Prediktív analitika}

\subsection{Modellek és metodológia}

Következő lépésként azt vizsgáltuk, hogy a két évben külön a bemeneti adatok alapján mennyire pontosan lehet előrejelezni egyes teljesítménymutatók értékét, illetve, hogy a predikciókra nézve a különböző bemeneti változók, más néven attribútumok, milyen és mekkora szereppel bírnak. Ehhez többféle modellen többféle \textit{gépi tanuláson alapuló osztályozó algoritmus} használatára volt szükség. A kutatás során kétféle eredmény alaposabb vizsgálatára összpontosítottunk mindkét évben: a "Matematika A1a - Analízis" tárgyból kapott érdemjegyre illetve az első félév végén megállapított kumulált tanulmányi átlagra. Ezen feladatok a felügyelt gépi tanulási problémák közé esnek, ahol a kitüntetett célváltozót szeretnénk a többi bemeneti változóval előrejelezni\cite{bevadat}. Ekkor a gépi tanulás során a teljes adathalmazt tanító és teszthalmazra bontjuk, a tanító adathalmazon betanítjuk az algoritmusokat úgy, hogy a tanítóhalmazbeli adatok célváltozóját minél pontosabban prediktálják, majd valamilyen metrika szerint kiválasztjuk a betanított algoritmusok közül a legjobbat. Az optimális osztályozó kiválasztásához többnyire \textit{keresztvalidációt} alkalmazunk. Keresztvalidáció során a tanítóhalmazt felbontjuk $K$ egyenlő részre, melyek közül az egyiket kinevezzük validációs halmaznak. Ezt követően az algoritmusokat betanítjuk a maradék $K$-$1$ részen, amelyeket aztán a validációs halmazon kiértékelünk. Ezt összesen $K$ alkalommal ismételjük, mindig másik részt választva validációs halmaznak, majd azt az algoritmust dedikáljuk a legjobbnak, amelynek az aggregált teljesítménye a $K$ darab iteráció során a legjobb. Az így kapott osztályozót még visszamérjük a teszthalmazon is az általánosítóképesség ellenőrzése végett. %A kutatás során a cél a teszthalmazon való minél hatásosabb előrejelzés mellett az egyes éveknél használt és optimalizált algoritmusok esetén a különböző attribútumok prediktív erejének összehasonlítása volt.

A két vizsgált probléma közül az előbbi alapvetően egy osztályozási probléma öt osztállyal, míg az utóbbi egy regressziós feladat. Az előbbi feladathoz ötféle algoritmust, \textit{Gradient Tree Boosting-ot, Naive Bayes-t, logisztikus regressziót, SVM-et} és \textit{lineáris regressziót} használtunk, az utóbbihoz pedig lineáris regressziót és Gradient Tree Boosting-ot (ezen algoritmusok működése és optimalizálása a következő fejezetben lesz ismertetve). Azért esett a választás ezen algoritmusokra, ugyanis számos egyetemi teljesítményt és lemorzsolódást vizsgáló tanulmány során teljesítettek kiváló eredménnyel \cite{modeling1, modeling2, modeling3, modeling4}. Mivel azonban viszonylag kevés adat állt a rendelkezésünkre, ezért az érdemjegyek prediktálásánál az adatrekordok esetén a pontos érdemjegy helyett érdemjegy csoportok előrejelzésére koncentráltunk. A matematika érdemjegycsoportok prediktálására így kétféle modell került felvázolásra: egy \textit{3 csoport modell}, illetve egy \textit{2 csoport modell}.

A 2 csoport modell esetén a két csoportot a \{5,4,3\} illetve \{2,1\} osztályok adják, míg a 3 csoport modellnél az osztályok \{5,4\}, \{3,2\} illetve \{1\} módon alakultak. Az előbbi esetben az osztályok intuitívan a lemorzsolódási veszélyeztetettség szerint formálódtak, míg az utóbbiban egy általánosabb "jól teljesítő", "rosszul teljesítő", "lemorzsolódott" csoporthármast kívántunk elérni. Mindkét modell esetén külön vizsgáltuk a teljesítményt összes hallgatóra vonatkozólag illetve szétbontva vegyészmérnök és biomérnök hallgatókra egyaránt (a környezetmérnökökről nem állt rendelkezésre elég adat, így őket a szakonkénti bontásban kihagytuk).

A használandó osztályozó algoritmusok közül a Naive Bayes és Gradient Tree Boosting algoritmusok képesek kezelni a többosztályos feladatokat, a lineáris regresszió azonban folytonos célváltozóérték prediktáláshoz használható, így ott a prediktált értéket kerekítettük a legközelebbi címkeértékhez. A logisztikus regresszió és az SVM alapjáraton csak bináris osztályozásra alkalmas, így a náluk \textit{One-vs-Rest} elvű osztályozást használtunk. Az elv lényege, hogy minden osztály esetén képezünk egy új virtuális osztályt, amely az összes többi osztályt tartalmazza, majd minden ilyen osztálypár esetén a bináris osztályozó meghatározza a kérdéses adatrekord esetén az osztályba tartozási valószínűségeket. Végül azt a címkét prediktáljuk a rekordnak, amely osztály esetén a legnagyobb ez a valószínűség. 

Az egyes modellek és almodellek esetén a tanítás előtt főkomponens analízist (Principal Component Analysis) is alkalmaztunk. Az eljárás lényege, hogy az adatpontokat egy kisebb dimenziós térre vetítjük le oly módon, hogy a változók közötti variancia minél nagyobb részét tartsák meg, így minimalizálva az információveszteséget\cite{PCA}. Az új változók, amelyeket főkomponenseknek nevezünk, a kisebb dimenziós térben az eredeti változók tapasztalati kovarianciamátrixának sajátvektorai lesznek. PCA használata során az algoritmusok gyorsabban tanulnak a kisebb dimenziószám miatt, és olykor jobb eredményt is érnek el. Jelen kutatásban másrészt azért is döntöttünk a PCA alkalmazása mellett, mert a korábbi, ugyanezen problémakört vizsgáló, általunk átnézett tanulmányok nem használtak PCA-t még nagyobb attribútum szám esetén sem, ugyanakkor mi a korai tanító-tesztelési fázisnál azt tapasztaltuk, hogy az áttranszformált adatokon jobban teljesítenek az osztályozó algoritmusok, így potenciálisan megéri alkalmazni.

\subsubsection*{Implementálás}

A vizsgálatokat Python-ban végeztük el az \textit{Sklearn}\cite{sklearn} csomag használatával. A \textit{jegycsoportok} prediktálására épített modellezési struktúrát a \ref{fig:modell}. ábra mutatja. Az egyes csoportmodelleknél a teljes adathalmazt felbontottuk tanító- és teszthalmazra 70-30 arányban, majd a tanítóhalmazra illesztett PCA modellt alkalmaztuk a teszthalmazra is, ahol a főkomponensek számát minden modellnél 2 és 8 között iterálva változtattuk 2-es lépésközzel. Ezt követően a változókat kvantilis alapú [0-1] uniform skálázásnak vetettük alá a tanítóhalmazra illesztett tapasztalati eloszlásfüggvények szerint, valamint az érdemjegy csoportok prediktálásához a 2 és 3 csoport modelleknél a célváltozó-értékeket rendre 1, 0-ra illetve 3, 2, 1-re módosítottuk. 

\begin{figure}[h]
\centering
\includegraphics[scale=0.6]{kepek/flowchart.png}
\caption{A jegycsoportokra irányuló modellezési struktúra sematikus ábrája}
\label{fig:modell}
\end{figure}

\newpage
Valamennyi algoritmus hiperparamétereinek optimális megválasztására 5-szörös keresztvalidációt alkalmaztunk, ahol törekedtünk arra, hogy az adatrekordok címkéjének eloszlása egyenletes legyen a felosztott részek között. A keresztvalidációnál használt, jóságot mérő metrikának a kiegyensúlyozott pontosságot ('\textit{balanced accuracy}') választottuk, amelynek képlete az alábbi:
\begin{align}
\text{balanced-accuracy} = \frac{1}{2}\left(\frac{TP}{TP+FN} + \frac{TN}{TN+FP} \right) 
\end{align}Ezen metrika alapvetően bináris, pozitív-negatív osztályú osztályozási problémákhoz alkalmas, de többosztályos osztályozás esetén is használható, ahol az egyes osztályokhoz tartozó \textit{TP, FP, FN, TN} értékek által kiszámított kiegyensúlyozott pontosságok számtani közepét nézzük. A képlet egyes jelölései két valamint több osztály esetén:  \\ \\
- \textbf{TP} a pozitívnak (osztálybelinek) osztályozott, valóban pozitív (osztálybeli) adatrekordok száma \\
- \textbf{FP} a pozitívnak (osztálybelinek) osztályozott de valójában negatív (nem osztálybeli) adatrekordok száma \\
- \textbf{FN} a negatívnak (nem osztálybelinek) osztályozott de valójában pozitív (osztálybeli) adatrekordok száma \\
- \textbf{TN} a negatív (nem osztálybelinek) osztályozott, valóban negatív (nem osztálybeli) adatrekordok száma \\ 
\\
A választott metrika mellett meghatároztuk a legjobb algoritmusokat, amelyeket a teszthalmazon visszamértünk, valamint kiértékeltük az ily módon választott modellek esetén az egyes változók fontosságát is.

Az \textit{első féléves kumulált átlag} predikciójánál a tisztított adathalmazt ugyanúgy 70-30 arányban osztottuk fel. Adattranszformálásra csak skálázást alkalmaztunk, PCA-t nem, majd valamennyi osztályozó hiperparamétereinek optimalizálása hasonlóan 5-szörös keresztvalidációval történt. Az illesztett legjobb modelleknél mindkét évben feljegyeztük a reziduális tagok szórásdiagramját, az egyes változók prediktív erejét, valamint az alábbi statisztikák értékét\cite{bolla_stat}
\begin{itemize}
\item[•] $R^2$: A modell hatásfokát mérő mutató, értéke [$-\infty,1$] közötti:
\begin{align}
R^2 = 1 - \frac{\sum_i (y_i - \hat{y}_i)^2}{\sum_i (y_i - \overline{y})^2}
\end{align} 
ahol $y_i$ és $\hat{y}_i$ rendre az i-edik adatrekord valódi és prediktált célváltozóértéke, $\overline{y}$ pedig a valódi célváltozóértékek átlaga.
\item[•] $MAE$: Átlagos abszolút eltérés (A keresztvalidáció során ez volt a használt mérőszám is):
\begin{align}
MAE = \frac{1}{n}\sum_i^n |y_i -\hat{y}_i| 
\end{align}
\item[•] $RMSE$: Gyököt vont átlagos négyzetes eltérés:
\begin{align}
RMSE = \sqrt{\frac{1}{n}\sum_i^n (y_i - \hat{y}_i)^2}
\end{align}
\end{itemize}





%TODO: Recall definícióját ismertetni?

\subsection{Osztályozó algoritmusok és optimalizálásuk}

\subsubsection{Lineáris regresszió}

A lineáris regresszió jellegéből adódóan alapvetően folytonos célváltozó prediktálására alkalmas, ugyanakkor kategorikus, ordinális címkéjű adatok osztályozására is fel lehet használni. Az algoritmus lényege, hogy a magyarázóváltozók mindegyikéhez egy-egy súlyt rendelünk, majd az adatpont attribútumértékeinek vesszük a súlyokkal való súlyozott összegét, és esetleg egy bias tagot hozzáadva az így kapott szumma lesz a prediktált címkeérték. A cél a tanítás során a súlyok optimális megtalálása, miközben a tanítóhalmazon minimalizáljuk a célváltozóérték és a prediktált érték közötti négyzetes hibát.

Mivel az algoritmus implementálása során a legkisebb négyzetek elvét alkalmazza, amellyel az optimális megoldás analitikusan elérhető, ezért nem történt hiperparaméter-optimalizáció.

\subsubsection{Naive Bayes}

%A Naive Bayes azon tényből indul ki, hogy a minimális osztályozási hibát akkor kapjuk, ha minden adatrekordhoz azt a $c$ címkét rendeljük, amelyre a $\mathbb{P}(C=c|\underline{X} = \underline{x})$ feltételes valószínűség maximális, ahol $\underline{X}=(X_1,X_2, \dots ,X_k)$ jelöli az attribútumokat, $\underline{x} = (x_1, x_2, \dots , x_k)$ az adatrekordhoz tartozó attribútumvektort, $C$ pedig a célváltozót. Vagyis a keresett optimális $c^*$ címkére az alábbi teljesül:
%\[
%c^* = \argmax_c \mathbb{P}(C=c|\underline{X} = \underline{x})
%\]
%
%Ez a Bayes-tétel és a teljes valószínűség tétele segítségével az alábbi formára hozható:
%\[
%c^* = \argmax_c \mathbb{P}(\underline{X} = \underline{x}|C=c) \cdot \mathbb{P}(C=c)
%\] 
%A Naive Bayes algoritmus naívan azzal a feltételezéssel él, hogy az attribútumok a célváltozó ismeretében feltételesen függetlenek, így ekkor a feltételes valószínűség felbontható szorzatra:
%\[
%\mathbb{P}(\underline{X}|C) = \mathbb{P}(X_1|C) \cdot \mathbb{P}(X_2|C) \cdot \dots \cdot \mathbb{P}(X_k|C)
%\]
%
%Ekkor a $\mathbb{P}(X_i=x_i|C=c_j)$ és $\mathbb{P}(C=c_j)$ valószínűségeket a tanító adatokból már meg tudjuk becsülni:
%\begin{align*}
%\mathbb{P}(X_i=x_i|C=c_j) &= \frac{n_{ij}}{n_j} \\
%\mathbb{P}(C=c_j) &= \frac{n_j}{n}
%\end{align*}
%ahol: \\
%- $j$ a lehetséges címkék száma, $n$ az összes tanító adatrekord száma.  \\
%- $n_{ij}$ azon tanító adatrekordok száma, amelynek $i$-edik attribútuma $x_i$ és a címkéje $c_j$. \\
%- $n_j$ pedig a $c_j$ címkéjű tanító adatrekordok száma. \\


A Naive Bayes algoritmus működése mögött álló alapelv az, hogy feltesszük az attribútumok feltételes függetlenségét, amennyiben a célváltozó értéke ismert. Osztályozás során azt vizsgáljuk, hogy mely címkeérték mellett a legnagyobb a valószínűsége annak, hogy az adott adatrekord attribútumai éppen a felvett értékeket kapták. A megfelelő valószínűségeket a tanítóhalmazbeli adatok attribútumértékeinek különböző címkék melletti relatív gyakoriságai adják. 

Az algoritmus a jellegéből adódóan nem igazán optimalizálható, így a Naive Bayes esetén nem történt keresztvalidáció.

\subsubsection{Gradient Tree Boosting}

A Gradient Boosting algoritmus egy \emph{ensemble} típusú osztályozó, amelynek lényege, hogy sok gyenge teljesítményű prediktor (\textit{"weak learner"}) eredményét felhasználva hoz létre egy erős prediktort \cite{friedman}. Gradient Tree Boosting esetén a gyenge prediktorok \textit{döntési fák}, amelyek lefelé irányított, legtöbbször bináris fák, továbbá minden belső csúcsban egy attribútumra vonatkozó feltétel szerepel, a levelek pedig valamilyen célváltozóértékkel címkézettek. Az adatrekordok osztályozása intuitívan a fán való végigvezetéssel történik, végül azt a címkét prediktálva nekik, amilyen címkéjű levélbe jutottak.

A boosting eljárás során minden fázisban egy új döntési fát építünk, amely megpróbálja az előző fázisban épített fa hibáit csökkenteni az úgynevezett reziduálisokra építve. A cél egy erős prediktorként funkcionáló döntési fa létrehozása ráerősítések sorozata révén. Az algoritmus alkalmas osztályozási és regressziós problémák megoldására is, előbbi esetben a cél a levelekben az adatrekordok címke szerinti homogenitásának maximalizálása, utóbbinál pedig a szórás minimalizálása az egy levélbe kerülő rekordok célváltozójára nézve. \\

%Legyen $F_{m-1}$ az $m$-$1$-edik fázisban kapott modell, majd jelölje $h_m(x)$ az $m$-edik fázisban épített döntési fát. Jelölje $J_m$ ennek a fának levélszámát illetve jelölje $R_{1m},\cdots,R_{J_mm}$ a bementi adatok terének egy felosztását a levelek alapján. 


\noindent A keresztvalidálás során optimalizált paraméterek: \\
- Tanulóráta (0.01 és 5 között változtatva 0.1-es lépésközzel)\\
- Boosting fázisok száma (5 és 100 között változtatva 5-ös lépésközzel)\\
- Facsúcsokban használt vágási feltétel (négyzetes hiba, Friedman MSE) \\
- Fák maximális mélysége (3,4,5 és 6 között változtatva) \\

\subsubsection{Logisztikus regresszió}

%A logisztikus regresszió nevéből adódóan egy regressziós algoritmus, tehát folytonos célváltozóértéket prediktál, azonban bináris osztályozásra használják. Alapja a \textit{szigmoid} függvény, amelynek értelmezési tartománya a valós számok halmaza, értékkészlete pedig a $(0,1)$ intervallum.
%%\begin{minipage}{•}
%\begin{align}
%\sigma(z) = \frac{1}{1+e^{-z}}
%\end{align}
%%\end{minipage}
%Legyen az $n$ darab tanító adatunk $(\underline{x}_1,y_1),(\underline{x}_2,y_2), \dots , (\underline{x}_n,y_n)$, ahol \\ $\underline{x}_i=(x_{i1},x_{i2}, \dots , x_{ik})$ az $i$-edik tanítóadat $k$ hosszú attribútumvektora, $y_i$ pedig az ehhez tartozó célváltozóérték. A cél az, hogy olyan $\underline{w} = (w_1,w_2, \dots , w_k) \text{ és } b$ súlyokat találjunk, amelyek esetén az összesített hiba értéke minimális. Egy adatrekord esetén a logaritmikus hiba adott súlyokkal:
%\begin{align}
%cost_{w,b}(\underline{x}_i) =  -y_i\log \left( \sigma(\underline{w}^T\underline{x}_i+b) \right) -(1-y_i)\log(1-\sigma(\underline{w}^T\underline{x}_i+b))
%\end{align}
%Az összes adatrekordra vonatkozó, végcélként minimalizálandó hibafüggvény pedig az alábbi:
%
%\begin{align}
%C(\underline{w},b) = -\frac{1}{n}\sum_{i = 1}^n \left( y_i\log \left( \sigma(\underline{w}^T\underline{x}_i+b) \right) +(1-y_i)log(1-\sigma(\underline{w}^T\underline{x}_i+b))\right)
%\end{align}
%
%Sok esetben ez a hibafüggvény még kiegészül egy $\lambda||(\underline{w},b)||^2$ ( ahol$||(\underline{w},b)||$ a \\ $(w_1,w_2, \dots , w_k, b)$ súlyvektor hossza) \textit{regularizációs taggal}, amely segít megakadályozni azt, hogy egyes súlyok túl nagy értéket vegyenek fel, így megelőzve a túltanulást. Itt $\lambda$ az állítható, valós \textit{regularizációs hiperparaméter}, amelyet minél nagyobbra állítunk, annál jobban bünteti a túltanulást.
%
%Ha a $k$ hosszú attribútumvektorainkat egy $k$-dimenziós tér pontjaiként fogjuk fel, a logisztikus regresszió ezekkel a súlyokkal lényegében egy optimális, lineárisan szeparáló $\underline{w}^T\underline{x}+b=0$ hipersíkot keres. Ha az $i$-edik adatrekordra $\underline{w}^T\underline{x}_i+b>0$, akkor azt pozitív 1-es  osztályba sorolja, ha pedig $\underline{w}^T\underline{x}_i+b<0$ akkor pedig a negatív 0-ás osztályba sorolja az osztályozó. A keresztvalidálás során optimalizált paraméterek: \\
%- Regularizációs paraméter (0.05 és 5 között változtatva 0.05-ös lépésközzel) \\
%- Önoptimalizálási módszer ("SAG", "SAGA") 


A logisztikus regresszió alapvetően bináris osztályozási problémák megoldására alkalmas, de kiterjeszthető többosztályos feladatok megoldására is. Lényege, hogy a lineáris regresszióhoz hasonlóan az adatrekord attribútumértékeinek súlyozott összegét használjuk egy szigmoid\footnote{A szigmoid függvény: $\sigma(z)=\frac{1}{1+e^{-z}}$, ahol $z=x_1w_1+x_2w_2+ \dots +x_nw_n+b$ a súlyozott összeg.} függvény bemeneteként, amelyet a függvény leképez a $\left(0,1\right)$ intervallumra, és amennyiben az output 0.5-nél nagyobb, úgy a pozitív osztályba soroljuk az adott rekordot, különben a negatívba. A cél nyilván itt is az optimális súlyok megtalálása, amellyel a félreosztályozási hibát minimalizáljuk. \\

\noindent A keresztvalidálás során optimalizált paraméterek: \\
- Regularizációs paraméter (0.05 és 5 között változtatva 0.05-ös lépésközzel) \\
- Önoptimalizálási módszer ("SAG", "SAGA") 

\subsubsection{SVM}

%Az SVM ('Support Vector Machine', magyarul 'Tartó Vektor Gép') algoritmus a logisztikus regresszióhoz hasonlóan egy lineárisan szeparáló hipersíkot akar meghatározni. Működési elve, hogy az alacsonyabb dimenziós adatpontokat különböző \textit{magfüggvények} segítéségével magasabb dimenzióba transzformálja át, és ebben a magasabb dimenziós térben keresi a szeparáló hipersíkot. Továbbá a hipersík keresése közben arra törekszik az algoritmus, hogy maximalizálja a \textit{margót}, azaz az elválasztó hipersíkkal párhuzamos hipersíkok által meghatározott maximális olyan térrészt, amely nem tartalmaz adatpontot. 
%
%A korábbi jelöléseket használva legyenek a már áttranszformált adatpontjaink $(\underline{x}_1,y_1),$ $(\underline{x}_2,y_2), \dots , (\underline{x}_n,y_n)$, amelyek egy $k$ dimenziós térben vannak, illetve legyenek a hipersíkhoz keresendő paraméterek $\underline{\theta}=(\theta_1, \theta_2, \dots , \theta_k)$ és $b$. Ekkor a hibafüggvény így írható fel:
%\begin{align}
%Err(\underline{\theta},b) = C \sum_{i=1}^n (y_icost_1(\underline{\theta}^T\underline{x}_i+b)+(1-y_i)cost_0(\underline{\theta}^T\underline{x}_i+b)) + \frac{1}{2}||(\underline{\theta} ,b)||^2
%\end{align}
%ahol a $C$ egy regularizációs paraméter, illetve a szummában szereplő költségfüggvények (amelyet \textit{zsanérhibának} nevezünk) az alábbiak:
%\begin{align}
%cost_j(\underline{\theta}^T\underline{x}+b) = \begin{cases} max\{0, 1-(\underline{\theta}^T\underline{x}+b)\} & \text{ha }j=1 \\
%                                                           max\{0, 1+(\underline{\theta}^T\underline{x}+b)\} & \text{ha }j=0 \end{cases} \\
%\end{align}



Az SVM (Support Vector Machine) algoritmus a logisztikus regresszióhoz hasonlóan egy lineárisan szeparáló hipersíkot akar meghatározni\cite{svm}. Lényege, hogy különböző magfüggvények segítségével az adatrekordokat egy magasabb dimenziós térbe képzi le, ahol olyan szeparáló hipersíkot keres, amely maximalizálja a vele párhuzamos hipersíkok által meghatározott olyan térrészt, amely adatpontot nem tartalmaz. A cél a megfelelő magfüggvény és az optimális hipersík megtalálása, amellyel a különböző címkéjű adatpontok lineárisan szeparálhatóak. \\

\noindent A keresztvalidálás során optimalizált paraméterek: \\
- Regularizációs paraméter (0.1 és 5 között változtatva 0.1-es lépésközzel)\\
- Magfüggvény (lineáris, legfeljebb 3-ad fokú polinomiális, RBF)



%
%\subsection{Implementálás és optimalizálás}
%
%
%%Fontosabb optimalizációs lépések csak a 2-3 csoport modellek esetén történtek. A Naive Bayes és lineáris regresszió algoritmusoknál jellegük és/vagy implementálásuk végett nem történt optimalizálás, a többi algoritmus esetén az alábbi hiperparaméterek kerültek változtatásra:
%\begin{itemize}
%\item[•] \textbf{kNN}: \\
%- Távolságmérték (euklédeszi, Mahalanobis) \\
%- Szomszédok száma (5 és 15 között változtatva) \\
%- Szomszéd címkeértékének súlyozása (uniform, távolság reciprokra, távolság reciproknégyzete) 
%\item[•] \textbf{Gradient Tree Boosting}: \\
%- Tanulóráta (0.01 és 5 között változtatva 0.1-es lépésközzel)\\
%- Boosting fázisok száma (5 és 100 között változtatva 5-ös lépésközzel)\\
%- Vágási feltétel (négyzetes hiba, Friedman MSE) \\
%- Maximális famélység (3,4 és 5)
%\item[•] \textbf{Logisztikus regresszió}: \\
%- Regularizációs paraméter (0.05 és 5 között változtatva 0.05-ös lépésközzel) \\
%- Önoptimalizálási módszer ("SAG", "SAGA") 
%\item[•] \textbf{SVM}: \\
%- Regularizációs paraméter (0.1 és 5 között változtatva 0.1-es lépésközzel)\\
%- Magfüggvény (lineáris, legfeljebb 3-ad fokú polinomiális, RBF)
%\end{itemize}

\newpage

\section{Modellek kiértékelése}

\begin{table}[H]
\centering
\begin{tabular}{ccc|ccccc}

    &&&\multicolumn{5}{c}{Osztályozó algoritmusok} \\
    &&& Grad. Boost. &  Naive B. & Log. reg.  &  SVM & Lin. reg. \\ 
        \hline
    \multirow{8}{*}{3 csoport}& \multirow{4}{*}{Összesített}&2 PC&66.67&62.67&52.00&58.67&61.33 \\
    												&&4 PC&\textbf{70.67}&60.00&57.33&53.33&65.33\\
    												&&6 PC&65.33&62.67&54.67&68.00&64.00\\
    												&&8 PC&64.00&68.00&53.33&62.67&64.00\\\cline{3-8}%\cdashline{4-8}
    						& \multirow{4}{*}{Szakonként}&2 PC&78.71&80.36&73.85&67.24&80.36 \\
    												&&4 PC&75.41&80.36&47.80&65.59&78.71\\
    												&&6 PC&\textbf{82.02}&80.36&75.47&67.21&82.02\\
    												&&8 PC&80.36&78.71&37.42&75.44&78.71\\
    						 
    \hline
    \hline
    \multirow{8}{*}{2 csoport}& \multirow{4}{*}{Összesített}&2 PC&59.42&69.57&69.57&72.46&69.57\\
    												&&4 PC&59.42&71.01&\textbf{73.91}&69.57&73.91\\
    												&&6 PC&63.77&69.57&73.91&71.01&73.91\\
    												&&8 PC&68.12&69.57&71.01&73.91&72.46\\\cline{3-8}
    						 & \multirow{4}{*}{Szakonként}&2 PC&67.31&67.31&65.69&62.41&64.03\\
    												&&4 PC&64.00&64.00&67.31&67.31&63.97\\
    												&&6 PC&64.03&65.69&64.07&65.65&67.27\\
    												&&8 PC&64.07&62.51&57.49&67.34&\textbf{68.96}\\
    												\hline
\end{tabular}
\caption{A 2019-es adatsor eredményei}
\label{tab:multicol1}
\end{table}

Először a \textbf{jegycsoportok} prediktálásának eredményeit ábrázoljuk. A \ref{tab:multicol1}. táblázatban a 2019-es adatokra optimalizált modellek teljesítménye látható, ahol az első három oszlop a modellt és a használt főkomponensek (PC) számát mutatja, míg a jobb oldali öt oszlop az optimalizált algoritmusok teljesítményét szemlélteti. A szakonkénti bontásban szereplő értékek a biomérnöki és vegyészmérnöki adatokon kapott értékek átlagai súlyozva az egyes szakokon tanuló hallgatók számával. Az algoritmusok többségének hatásfoka 60-80\% közé tehető. A 3 csoport modellek esetén a Gradient Tree Boosting algoritmus, míg a 2 csoport modellek esetén a regressziós algoritmusok teljesítettek a legjobban, ugyanakkor a 2 csoport modellek teljesítménye többségében alulmúlja a 3 csoport modellekét. Mivel a 2 csoport modellben az osztályok eloszlása kiegyensúlyozottabb, ez arra enged minket következtetni, hogy a 2-es és 3-as érdemjegyet szerzők között a bemeneti adatok tekintetében nincsenek nagy különbségek.

A \ref{tab:multicol2}. táblázat a 2021-es adatokon optimalizált algoritmusok eredményét szemlélteti az előző ábráéval megegyező metodológia szerint. Ezen adathalmazon az osztályozók teljesítménye jobbnak mondható, mint a 2019-es adatsoron, átlagosan a legeredményesebb algoritmusnak a Naive Bayes nevezhető, amely a szakonkénti bontású 3 csoport modellen ért el minden főkomponensszám mellett 80\% feletti teljesítményt, ugyanakkor a 2 csoport modell esetén a regressziós és SVM algoritmusok is 80\% közeli vagy afölötti eredményt értek el. A 2019-es eredményekkel ellentétben a 2021-es adatokon a 2 csoport modellek értékei jobbak, mint a 3 csoport modelleké, ugyanakkor nem szignifikánsan.


\begin{table}[H]
\centering
\begin{tabular}{ccc|ccccc}

    &&&\multicolumn{5}{c}{Osztályozó algoritmusok} \\
    &&& Grad. Boos. &  Naive B. & Log. reg.  &  SVM & Lin. reg. \\ 
        \hline
    \multirow{8}{*}{3 csoport}& \multirow{4}{*}{Összesített}&2 PC&54.24&\textbf{80.39}&76.29&78.81&60.92 \\
    												&&4 PC&54.89&72.05&72.13&75.79&70.40\\
    												&&6 PC&66.24&76.44&70.04&76.94&70.62\\
    												&&8 PC&63.00&75.29&68.18&73.06&62.07\\\cline{3-8}%\cdashline{4-8}
    						 & \multirow{4}{*}{Szakonként}&2 PC&64.84&81.89&59.23&64.77&49.35\\
    												&&4 PC&55.55&\textbf{83.07}&66.69&66.66&67.91\\
    												&&6 PC&66.69&82.85&66.65&53.67&53.31\\
    												&&8 PC&59.26&82.96&68.51&62.95&55.53\\
    \hline
    \hline
    \multirow{8}{*}{2 csoport}& \multirow{4}{*}{Összesített}&2 PC&69.45&67.89&69.77&69.77&67.89 \\
    												&&4 PC&72.74&72.90&78.23&76.51&77.91\\
    												&&6 PC&67.89&72.90&79.80&79.80&76.19\\
    												&&8 PC&68.05&74.62&79.96&\textbf{83.24}&79.63\\\cline{3-8}
    						 & \multirow{4}{*}{Szakonként}&2 PC&60.23&77.41&72.87&73.01&79.68\\
    												&&4 PC&63.92&74.86&72.59&69.60&78.27\\
    												&&6 PC&67.61&77.84&81.08&76.42&\textbf{81.53}\\
    												&&8 PC&68.32&77.84&77.41&69.75&79.68\\
    												\hline
\end{tabular}
\caption{A 2021-es adatsor eredményei}
\label{tab:multicol2}
\end{table}


A két év modelljeinek összesített változófontosságait a \ref{fig:variables2}. ábra, míg az egyes modellekhez tartozó attribútumszignifikanciákat a \ref{fig:variables}. ábra szemlélteti.

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{kepek/eves_valtozok.png}
\caption{A változók összesített fontossága a két évben}
\label{fig:variables2}
\end{figure}

\newpage

\begin{figure}[H]
\centering
\includegraphics[scale=0.57]{kepek/modell_valtozo.png}
\caption{Az attribútumok prediktív ereje a legjobban teljesítő algoritmusoknál}
\label{fig:variables}
\end{figure}



%\newpage
%\begin{center}
%\begin{tikzpicture}
%	\draw (-10,-10) rectangle (-7,-9);
%	\draw[->] (-7,-9.5) -- (-5,-9.5);
%	
%\end{tikzpicture}
%\end{center}



\noindent A diagramokon szereplő értékek az egyes algoritmusoknál megállapított változófontosságok min-max skálázott értékei, amelyeket regressziós algoritmusoknál az attribútumokhoz rendelt súlyokból, a többi osztályozónál pedig az Sklearn \textit{'inspection'} csomagjának segítségével nyertünk ki. Az összesített ábrán az egyes évek legfontosabb attribútumai a megfelelő évek különböző modelljein is többnyire jelentős szignifikanciával bírnak, a többi változó fontossága viszont modellenként eltérő. A 0. ZH pontszám illetve az érettségi pont prediktív ereje mindkét évben kiemelkedő. A 2019-es évben az emelt matematika érettségi megléte és a matematika-nyelvi teszten elért eredmény is nem elhanyagolható szignifikanciával bírt, viszont 2021-ben ezen tényezők prediktáló ereje csökkent, ugyanakkor az elért tanulmányi- és többletpontok jelentősége a matematika jegyre nézve közel kétszeresére nőtt.

A félreosztályozások jellegéről több információval bírnak a \emph{tévesztési mátrixok}, amelyek a prediktált és valódi címke vonatkozásábán ábrázolják az egyes adatrekordok számát. A \ref{fig:confusion}. ábrán az összesített modelleknél legjobban teljesítő algoritmusok tévesztési mátrixai láthatóak, ahol a 3 csoport modellnél a 3, 2, 1 címkék rendre az \{5,4\}, \{3,2\}, \{1\} osztályokat, míg a 2 csoport modellnél az 1 és 0 címkék pedig az \{5,4,3\} és \{2,1\} osztályokat reprezentálják. Egy optimális osztályozó esetén csak az átlóban vannak nem nulla elemek, hisz akkor egyezik meg a prediktált és a valódi címkéje az adatoknak. Az ábrán jól látható módon míg 2021-ben a félreosztályozás mértékében az egyes osztályok között nincsenek számottevő különbségek, addig 2019-ben a 3 csoport modellnél a 4-5-ös osztálybeli adatrekordok nagyobb része 2-3-as osztályba lett besorolva (14 darab hallgató a 24-ből), valamint a 2 csoport modell esetén magas a hamisan 0-nak, azaz lemorzsolódásban veszélyeztetettnek osztályzott rekordok aránya. Ez azt mutatja, hogy az illesztett modellek sok esetben alulbecsülik a 2019-es hallgatók teljesítményét, amelynek az egyik oka az lehet, hogy az osztályok között vékonyak a határok a bemeneti adatok tekintetében.

\begin{figure}[H]
\centering
\includegraphics[width=.8\textwidth]{kepek/confusion_matrices.png}
\caption{Tévesztési mátrixok az összesített modellek esetén}
\label{fig:confusion}
\end{figure}

\newpage

A \textbf{kumulált átlag} lineáris regresszióval való prediktálásának eredményei (statisztikák, reziduális szórásdiagramok és az egyes változók prediktív ereje egymáshoz viszonyítva) a \ref{fig:kumulalt}. ábrán láthatóak. 

\vspace{0.5cm}



\begin{figure}[H]
    \centering
    \begin{minipage}[b]{0.4\textwidth}
    \begin{center}
    \textbf{2019}
    \end{center}
    \raggedright
    - $R^2$: 0.5462 \\
    - $MAE$: 0.3455 \\
    - $RMSE$: 0.4165 \\
    	\centering
        \includegraphics[width=1\textwidth, left]{kepek/residual2019.png} % first figure itself
        \includegraphics[width=1\textwidth, left]{kepek/kumulalt2019.png} % first figure itself
    \end{minipage}
    \begin{minipage}[b]{0.4\textwidth}
    \begin{center}
    \textbf{2021}
    \end{center}
    \raggedright
    - $R^2$: 0.5646 \\
    - $MAE$: 0.3710 \\
    - $RMSE$: 0.4415 \\
        \centering
        \includegraphics[width=1\textwidth, left]{kepek/residual2021.png} % first figure itself
        \includegraphics[width=1\textwidth, left]{kepek/kumulalt2021.png} % first figure itself
    \end{minipage}
   \caption{Lineáris regresszió eredménymutatói a két évben}
   \label{fig:kumulalt}
\end{figure}

\noindent Statisztikák tekintetében mindkét évben hasonló eredményeket kaptunk, amely azt mutatja, hogy a két évben hasonló hatékonysággal lehet a kumulált átlag eloszlását modellezni lineáris modellekkel, ugyanakkor csak közepes hatékonysággal. Ami kiemelendő, az a reziduális tagok eloszlása, amely mindkét évben hasonló alakzatot vesz fel, bár 2019-ben kicsivel nagyobb szórással. A változók prediktív erejét tekintve itt is fennáll az az érdemjegycsoportok prediktálásánál megállapított jelenség, miszerint a matematika-nyelvi teszt matematika részén elért eredmény 2019-ben magas szignifikanciával bírt, azonban 2021-ben ez a szignifikancia drasztikusan csökkent. Az érettségi pont mindkét évben igen fontos determináló tényező, ugyanakkor 2019-ben a hozott tanulmányi pontok is nagy szerepet játszanak az első féléves kumulált átlag meghatározásában.

A Gradeint Tree Boosting-gal való előrejelzés eredményei a lineáris regressziónál használt struktúra szerint a \ref{fig:kumulalt2}. ábrán láthatóak. 

\begin{figure}[H]
    \centering
    \begin{minipage}[b]{0.4\textwidth}
    \begin{center}
    \textbf{2019}
    \end{center}
    \raggedright
    - $R^2$: 0.7485 \\
    - $MAE$: 0.3059 \\
    - $RMSE$: 0.4253 \\
    	\centering
        \includegraphics[width=1\textwidth, left]{kepek/residual2019_2.png} % first figure itself
        \includegraphics[width=1\textwidth, left]{kepek/kumulalt2019_2.png} % first figure itself
    \end{minipage}
    \begin{minipage}[b]{0.4\textwidth}
    \begin{center}
    \textbf{2021}
    \end{center}
    \raggedright
    - $R^2$: 0.4696 \\
    - $MAE$: 0.3770 \\
    - $RMSE$: 0.4407 \\
        \centering
        \includegraphics[width=1\textwidth, left]{kepek/residual2021_2.png} % first figure itself
        \includegraphics[width=1\textwidth, left]{kepek/kumulalt2021_2.png} % first figure itself
    \end{minipage}
   \caption{Gradient Tree Boosting eredménymutatói a két évben}
   \label{fig:kumulalt2}
\end{figure}

\noindent Gradient Tree Boosting-ot használva a 2019-es modell statisztikái drasztikusan jobbak, mint a lineáris regressziónál számított értékek, ugyanakkor a 2021-es modell hatásfoka valamelyest csökkent. A reziduális tagok szórásképe a két évben igencsak eltérő. Ami megjegyzendő, hogy az egyes attribútumok egymáshoz viszonyított prediktív ereje a két évben közel azonos: a két legfontosabb változó a tanulmányi és érettségi pont, viszont a többi változó közül csak a 0. ZH pontszám rendelkezik nem elhanyagolható szignifikanciával.

\newpage 

\section{Diszkusszió, következtetések a modellezésről}

A matematika érdemjegyek prediktálása során sikeresebben megjósolhatóak a 2021-ben kezdett hallgatók teljesítményei, amely azt jelenti, hogy náluk kisebb az ingadozás és a variancia a bemeneti adatok tekintetében a célváltozóra nézve. Ugyanakkor a legjobb modellekkel is csak 80-85\% közötti hatásfok érhető el, amely bár kellően jobb, mint egy véletlen osztályzó által adott 33\%-os illetve 50\%-os eredmény, de még bizonyosan tovább növelhető. A teljesítmény több adatponttal és több, új bemeneti változó (középiskola földrajzi lokációja; nem; életvitellel kapcsolatos adatok stb.) vizsgálatával mindenképpen javítható lenne, ugyanakkor az új érettségi rendszer 2024-re esedékes bevezetésével érdemes ezek mellett új modellezési struktúrákat is kialakítani. Egy másik megoldás a teljesítmény növelésére egy ensemble modell lenne, amely az egyes kategóriákban legjobb teljesítő, előre meghatározott számú algoritmus eredményét vetné össze és súlyozná az algoritmusok hatásfokával, majd ezek alapján adna egy végső predikciót, ugyanakkor ez több időt és magasabb szintű optimalizációt venne igénybe. A bemeneti változók tekintetében a legfontosabb észrevétel, hogy 2021-ben drasztikusan megnőtt a felvételi pontszám jelentősége a matematika érdemjegyre nézve, viszont a kognitív készségek érdemjegyre gyakorolt hatásaiban csökkentek a különbségek a hallgatók között.

A kumulált átlag predikcióinál látható, hogy a két legjobban domináló tényező mindkét évben a tanulmányi és az érettségi pont, a többi attribútum pedig változó, de többnyire elhanyagolható szignifikanciával bír. Az is észrevehető, hogy egy "black box", nehezebben értelmezhető modell, mint a Gradient Tree Boosting algoritmus, sokkal több információt tud kinyerni az érettségi és tanulmányi pontokból a kumulált átlagra nézve, mint a lineáris regresszió, így további modellezések során célszerű az előbbit használni, esetleg más ensemble módszereket alkalmazni. Ugyanakkor a lineáris regressziót érdemes lehet kibővíteni harmad- vagy negyedfokú polinomiális regresszióvá, vagy kombinálni az osztályozófüggvényt valamilyen trigonometrikus függvénnyel, hisz a lineáris regressziónál kapott két szóráskép hasonló görbét ír le, s így pontosabb eredményekhez juthatunk mindkét évben. Természetesen a teljesítmény több adatponttal és több változóval itt is potenciálisan tovább javítható lenne. 

Egy fontos és nem triviális kérdés az, hogy ezeket az eredményeket milyen módon lehet felhasználni. Egyfelől a különböző attribútumok prediktív erejének változását figyelembe véve a célszerű lenne az egyetemek (jelen esetben főként a BME) tanrendébe illetve felvételi rendszerébe beépíteni az észrevételeket. A 2024-es felvételi eljárás módosításának köszönhetően az egyetemek nagyobb szabadságot kapnak a felvételi pontok számítását illetően, így a szabadon kiosztható 100 pont keretein belül az észrevételek felhasználásra kerülhetnének. Amennyiben a dolgozatban taglalt kutatást kiterjesztenénk több egyetem hallgatóinak vizsgálatára is, akkor akár egyetem-specifikus változtatásokat is meg tudnánk határozni. Egy másik felhasználási mód az lenne, hogy az optimális modellekkel még a szemeszter elején kiszűrjük a nagy valószínűséggel lemorzsolódó hallgatókat, és esetleg felzárkóztató kurzusukat kínáljunk nekik. Ami fontos szempont, hogy ezt mennyire etikus formában lehet megvalósítani, hiszen ha rögtön év elején azzal szembesítjük hallgatót, hogy nagy valószínűséggel lemorzsolódik, az egyes személyeknél demoralizálóan tud hatni, és képes rányomni a bélyegét a hosszútávú egyetemi teljesítményükre. Ezt a problémát részben orvosolhatná az, ha az egyes változók fontosságát és a modellezés, osztályozás folyamatát adott bemeneti paraméterek mellett az egyszerű felhasználó számára is világos, könnyen értelmezhető, esetleg interaktív módon tudnánk vizualizálni. Molontay et al. \cite{molontay1, molontay2} révén korábban már készültek kutatások, amelyek a magyar felsőoktatási felvételi rendszerben használt bemeneti adatok értelmezhetőségének javítására irányultak a későbbi egyetemi teljesítmény ismeretében. Az általuk vázolt metodológiával összhangban a LIME \cite{lime} és SHAP \cite{shap} Python könyvtárak megfelelő adatvizualizáció mellett remek megoldást nyújthatnának erre a problémára. 



\section{Összefoglalás}


Munkánkban modern adattudományi eszközökkel vizsgáltuk a 2019-ben és 2021-ben beiratkozott elsőéves BME VBK hallgatók első félév végi teljesítményében és bemeneti adataiban fellépő különbségeket. A dolgozat első felében először különféle szórás- és oszlopdiagramok segítségével vizsgáltuk a két év adataiban fellépő eltéréseket, majd többféle folyamatábrával és klaszterezési kísérlettel folytattuk az elemzést mélyebb kapcsolatokat keresve. Az ábrák ugyan rávilágítottak néhány fontosabb összefüggésre, viszont a részletesebb elemzések szükségességét is megerősítették.

A dolgozat második felében prediktív analitikai módszerekkel vizsgáltuk az egyes bemeneti adatok fontosságának változását első félév végi teljesítménymutatókra nézve, valamint annak a hatásfokát, hogy ezen mutatók értékei mennyire jól előrejelezhetők. A modellezés során az egyes prediktáló algoritmusok mellett főkomponens analízist is alkalmaztunk. Az eredményekből az szűrhető le, hogy a 2021-ben kezdett hallgatók eredményei ugyan romlottak a járvány kitörése előtti szinthez képest, ugyanakkor sok esetben pontosabban előrejelezhető a teljesítményük, valamint a felvételi pontszám jelentősebb prediktáló erővel bír az első féléves matematika jegyre és kumulált átlagra nézve, mint 2019-ben.

Legjobb tudásunk szerint ez az első olyan kutatás, amely ilyen elgondolással és metodológiával vizsgálja a hallgatók bemeneti adatainak megváltozását a pandémia előtti és utáni időszakban, így kutatásunk egyedülállónak mondható. További céljaink közé tartozik a kutatás többféle bemeneti változóval való kibővítése, új modellezési struktúrák és algoritmusok kipróbálása valamint az eredmények egyetem- és hallgatóbarát hasznosítása is.

\newpage
\begin{thebibliography}{9}
\bibitem{friedman}Jerome H. Friedman. Greedy function approximation: A gradient boosting machine. 
\textit{Annals of Statistics}, 29, 1189-1232.

\bibitem{modeling1}Jovial Niyogisubizo, Lyuchao Liao, Eric Nziyumva, Evariste Murwanashyaka, Pierre Claver Nshimyumukiza.
Predicting student's dropout in university classes using two-layer ensemble machine learning approach: A novel stacked generalization.
\textit{Computers and Education: Artificial Intelligence}, Volume 3, 100066, 2022.

\bibitem{modeling2}Marina Segura, Jorge Mello, Adolfo Hernandez. (2022). Machine Learning Prediction of University Student Dropout: Does Preference Play a Key Role?. \textit{Mathematics}, Volume 10, 3359, 2022.

\bibitem{modeling3}Ahajjam Tarik, Haidar Aissa, Farhaoui Yousef. Artificial Intelligence and Machine Learning to Predict Student Performance during the COVID-19. \textit{Procedia Computer Science}, 184:835-840, 2021.

\bibitem{modeling4}D. K. Dake, D. D. Essel, J. E. Agbodaze. Using Machine Learning to Predict Students' Academic Performance During Covid-19. \textit{2021 International Conference on Computing, Computational Modelling and Applications}, pages 9-15, 2021.

\bibitem{sklearn} F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, E. Duchesnay. Scikit-learn: Machine Learning in Python. \textit{Journal of Machine Learning Research}, Volume 12, pages 2825-2830, 2011.

\bibitem{svm} C. Cortes, V. Vapnik. Support-vector network. \textit{Machine Learning}, Volume 20, pages 273–297, 1995.

\bibitem{bevadat} Roland Molontay. \textit{Lecture notes in Intorduction to Data Science.} Budapest University of Technology and Economics, 2021.

\bibitem{bolla_stat} Bolla Marianna, Krámli András.  \textit{Statisztikai következtetések elmélete.}  Elméleti matematika. Typotex Kft., 2012.

\bibitem{PCA}Jonathon Shlens. A Tutorial on Principal Component Analysis. \textit{CoRR}, abs/1404.1100, 2014.

\bibitem{molontay1}Máté Baranyi, Marcell Nagy, Roland Molontay. Interpretable Deep Learning for University Dropout Prediction. \textit{Proceedings of the 21st Annual Conference on Information Technology Education}, pages 13-19, 2020.

\bibitem{molontay2}Marcell Nagy, Roland Molontay. Comprehensive analysis of the predictive validity of the university entrance score in Hungary. \textit{Assessment \& Evaluation in Higher Education}, 46:8, 1235-1253, 2021.

\bibitem{student_perf1}J. Cavanaugh, S. Jacquemin, C. Junker. A look at student performance during the COVID-19 pandemic. \textit{Quality Assurance in Education}, Vol. ahead-of-print,  No. ahead-of-print, 2022. \url{https://doi.org/10.1108/QAE-01-2022-0008}

%\bibitem{student_perf2}E. Grewenig, P. Lergetporer, K. Werner, L. Woessmann, L. Zierow. COVID-19 and Educational Inequality: How School Closures Affect Low-and High-Achieving Students. \textit{EconStor}, 2020.

\bibitem{student_perf3}El-Sayed Atlam, Ashraf Ewis, M.M. Abd El-Raouf, Osama Ghoneim, Ibrahim Gad. A new approach in identifying the psychological impact of COVID-19 on university student’s academic performance. \textit{Alexandria Engineering Journal}, Volume 61, Issue 7, pages 5223-5233, 2022.

\bibitem{student_perf5}E.M. Onyema, N.C. Eucheria, F.A. Obafemi, S. Sen, F.G. Atonye, A. Sharma, A.O. Alsayed. Impact of coronavirus pandemic on education. \textit{Journal of Education and Practice}, Volume 11, pages 108-121, 2020.

\bibitem{student_perf6}Yamini Chandra. Online education during COVID-19: perception of academic stress and emotional intelligence coping strategies among college students. \textit{Asian Education and Development Studies}, Volume 10, No. 2, pages 229-238, 2020.

\bibitem{student_perf7}Kimkong Heng, Koemhong Sol. Online learning during COVID-19: Keychallenges and suggestions to enhance effectiveness. \textit{Cambodian Journal of Educational Research}, Volume 1, No. 1, pages 3–16, 2021.

\bibitem{student_perf8}Mohammad Alawamleh, Lana Mohannad Al-Twait, Gharam Raafat Al-Saht. The effect of online learning on communication between instructors and students during Covid-19 pandemic. \textit{Asian Education and Development Studies}, Volume 11, No. 2, pages 380-400, 2022.

\bibitem{student_perf9}K. Mukhtar, K. Javed, M. Arooj, A. Sethi. Advantages, Limitations and Recommendations for online learning during COVID-19 pandemic era. \textit{Pakistan Journal of Medical Sciences}, S27–S31, 2021. 

\bibitem{cov_solution3} Waqas Haider Bangyal, Rukhma Qasim, Najeeb ur Rehman, Zeeshan Ahmad, Hafsa Dar, Laiqa Rukhsar, Zahra Aman, Jamil Ahmad. Detection of Fake News Text Classification on COVID-19 Using Deep Learning Approaches. \textit{Computational and Mathematical Methods in Medicine}, Volume 2021, Article ID 5514220, 2021. \href{https://doi.org/10.1155/2021/5514220}{https://doi.org/10.1155/2021/5514220}

\bibitem{cov_solution2} Apurva Wani, Isha Joshi, Snehal Khandve, Vedangi Wagh, Raviraj Joshi. Evaluating Deep Learning Approaches for Covid19 Fake News Detection. \textit{CoRR}, abs/2101.04012, 2021. \href{https://arxiv.org/abs/2101.04012}{https://arxiv.org/abs/2101.04012}

\bibitem{cov_solution} Marianna Isaakidou, Emmanouil Zoulias, Marianna Diomidous. Machine Learning to Identify Fake News for COVID-19. \textit{Stud Health Technol Inform}, Volume 281, pages 108-112, 2021.

\bibitem{mlr_1}Akash Gupta, Amir Gharehgozli. Developing a machine learning framework to determine the spread of COVID-19 in the USA using meteorological, social, and demographic factors. \textit{International Journal of Data Mining, Modelling and Management}, Volume 14, No. 2, pages 89-109, 2022.

\bibitem{mlr_2}Y. Alali,F. Harrou, Y. Sun. A proficient approach to forecast COVID-19 spread via optimized dynamic machine learning models. \textit{Sci Rep}, 12, 2467, 2022.

\bibitem{student_perf4}Z. Malki, E.S. Atlam, A. Ewis, G. Dagnew, A.R. Alzighaibi, G. ELmarhomy, M.A. Elhosseini, A.E. Hassanien, I. Gad.
ARIMA models for predicting the end of COVID-19 pandemic and the risk of second rebound. \textit{Neural Comput \& Applic}, Volume 33, pages 2929–2948, 2021.

\bibitem{magyar1} Judit Monostori. The school year 2020-2021 in Hungary during the pandemic - Country report. \textit{Publications Office of the European Union}, Luxembourg, 2021.

\bibitem{magyar2} Proháczik Ágnes. A tantermi és az on-line oktatás (tanítás és tanulás) összehasonlító elemzése. \textit{Opus et Educatio}, Volume7. No.3, 2020. \url{http://opuseteducatio.hu/index.php/opusHU/article/view/390/672}

\bibitem{magyar3}P. Csépe, E. Dinya, P. Balázs, S. M. Hosseini, G. Küzdy, L. Rosivall. Impact of the first wave of COVID-19 pandemic on the Hungarian university students' social and health behaviour. \textit{Z Gesundh Wiss},  28:1-7, 2021.

\bibitem{shap}Scott Lundberg, Su-In Lee. A Unified Approach to Interpreting Model Predictions \textit{Advances in Neural Information Processing Systems 30}, Curran Associates Inc., pages 4765-4774, 2017.

\bibitem{lime}Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin. "Why Should \{I\} Trust You?": Explaining the Predictions of Any Classifier. \textit{Proceedings of the 22nd International Conference on Knowledge Discovery and Data Mining}, pages 1135-1144, 2016.

\end{thebibliography}

\end{document}

