\documentclass[12pt]{article}
 
\usepackage[T1]{fontenc}     
\usepackage[utf8]{inputenc}  
\usepackage[magyar]{babel}   
\usepackage{lmodern}
\usepackage{caption}        
 
\usepackage{amsmath,amssymb} 
\usepackage{amsthm}          
\usepackage{graphicx}  
\usepackage{hyperref}  
\usepackage[export]{adjustbox}
\usepackage{wrapfig}
\usepackage{float}
\usepackage[a4paper, left=25mm, right=25mm, top=25mm, bottom=25mm]{geometry}

\linespread{1.3}

\begin{document}
\begin{center}
\Huge{TDK dolgozat Kivonat}
\vspace{1.3cm}

\Large{Elsőéves VBK hallgatók teljesítményének vizsgálata a Covid előtti és utáni időszakból}
\vspace{0.8cm}

Köller Donát Ákos, Vlaszov Artúr
\end{center}
\vspace{1cm}

Az elmúlt évek Covid-19 járványa során elrendelt és bevezetett online oktatás nem minden középiskolában tudta elérni ugyanazt a hatásfokot, mint amelyet a jelenléti oktatás tudott nyújtani, s ez a tanulók későbbi, hallgatói teljesítményén is tapasztalható volt. A kutatás során azt vizsgáltuk adattudományi eszközökkel, hogy a 2021-es elsőéves BME VBK hallgatók bemeneti és első félév végi teljesítménye milyen módon változott a 2019-es elsőévesekéhez képest.

A dolgozat első felében a 2019-es és 2021-es évek adatain végzett adatelemzés kerül bemutatásra, ahol a többféle bemeneti adat és mérőszám egymáshoz való viszonyát és az adatrekordok klaszterezhetőségét vizsgáltuk és hasonlítottuk össze a két évben. A dolgozat második fele prediktív analitikával foglalkozik, ahol gépi tanulás segítségével első félév végi teljesítménymutatók prediktálhatóságát vizsgáltuk, illetve azt, hogy a predikciót végző algoritmusok és modellek esetén mely változók milyen mértékben befolyásolták a jósolt eredményt.



%Manapság a folyamatosan növekvő információmennyiség és az egyre nagyobb mértékű közösségi média használat miatt különösen fontos a különféle forrásból származó információk igazságtartalmának ellenőrzése. A Covid-19 pandémia alatt számtalan olyan hamis hír terjedt el, amely nehezítette a járványkezelést, és a tévinformáció terjedésének megakadályozása sokszor nehezebb feladat, mint egy járvány megfékezése. Szakdolgozatomban azt vizsgáltam, hogy gépi tanulás segítségével hogyan és milyen pontossággal lehet eldönteni egy Covid-19-cel kapcsolatos szövegről, hogy az abban szereplő információ hiteles-e vagy sem. 
%
%A szükséges adattudományi és természetes nyelvfeldolgozási fogalmak bevezetése után először megnézzük egy előre összeállított adathalmazon, hogy leíró statisztikákat tekintve milyen különbségek vannak megbízható és nem megbízható szövegek között. Ezután részletesen megismerkedünk két, nyelvi adatok elemzésére alkalmas eljárással: a TF-IDF modellel és a Word2Vec modellel. Az egyes modellek esetén megnézzük a modellezés sajátosságait, a megbízhatóságot osztályozó algoritmusok működését, a modellezési eljárások implementálását és az optimalizálás menetét, végül pedig a modellek teljesítményét a vizsgált adathalmazon.
%
%A TF-IDF modell legjobb osztályozói 90-95\%-os átlageredményt értek el különböző hatékonyságot mérő mérőszámok tekintetében (Pontosság, Recall, Precision), míg a Word2Vec modell algoritmusai 85-90\%-osat, amelyből az a következtetés vonható le, hogy jól elkülöníthető különbségek vannak a megbízható és a nem megbízható szövegek nyelvi struktúrájában. A szakdolgozat végén kitérünk néhány alkalmazási módra is az eredmények hasznosítása céljából, illetve számba veszünk pár lehetőséget a megbízhatóság vizsgálatának bővítésére.





\end{document}

